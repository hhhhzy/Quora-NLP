{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from scipy.spatial.distance import cosine\n",
    "from transformers import AutoModel, AutoTokenizer, Trainer, AutoModelForSequenceClassification, BertForSequenceClassification, BertConfig,BertModel\n",
    "from datasets import load_dataset, ClassLabel, Value, load_metric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare dataset for finetuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the tokenizer pretrained on bert-base\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"princeton-nlp/sup-simcse-bert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default\n",
      "Reusing dataset quora (C:\\Users\\52673\\.cache\\huggingface\\datasets\\quora\\default\\0.0.0\\36ba4cd42107f051a158016f1bea6ae3f4685c5df843529108a54e42d86c1e04)\n",
      "Using custom data configuration default\n",
      "Reusing dataset quora (C:\\Users\\52673\\.cache\\huggingface\\datasets\\quora\\default\\0.0.0\\36ba4cd42107f051a158016f1bea6ae3f4685c5df843529108a54e42d86c1e04)\n"
     ]
    }
   ],
   "source": [
    "# sampling the dataset for fine-tuning\n",
    "train = load_dataset(\"quora\", split = 'train[:35%]')     # classic 7/3 split\n",
    "validation = load_dataset(\"quora\", split = 'train[35%:50%]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at C:\\Users\\52673\\.cache\\huggingface\\datasets\\quora\\default\\0.0.0\\36ba4cd42107f051a158016f1bea6ae3f4685c5df843529108a54e42d86c1e04\\cache-0474a84a76505170.arrow\n",
      "Loading cached processed dataset at C:\\Users\\52673\\.cache\\huggingface\\datasets\\quora\\default\\0.0.0\\36ba4cd42107f051a158016f1bea6ae3f4685c5df843529108a54e42d86c1e04\\cache-387810a1332fde55.arrow\n"
     ]
    }
   ],
   "source": [
    "# convert the dtype of 'is_duplicate' to int\n",
    "new_features = train.features.copy()\n",
    "new_features[\"is_duplicate\"] = Value('int32')\n",
    "train = train.cast(new_features)\n",
    "\n",
    "new_features = validation.features.copy()\n",
    "new_features[\"is_duplicate\"] = Value('int32')\n",
    "validation = validation.cast(new_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at C:\\Users\\52673\\.cache\\huggingface\\datasets\\quora\\default\\0.0.0\\36ba4cd42107f051a158016f1bea6ae3f4685c5df843529108a54e42d86c1e04\\cache-94540c3e4c186fdb.arrow\n",
      "<ipython-input-10-47721646f2ed>:5: FutureWarning: rename_column_ is deprecated and will be removed in the next major version of datasets. Use Dataset.rename_column instead.\n",
      "  encoded_train.rename_column_(\"is_duplicate\", \"labels\")\n"
     ]
    }
   ],
   "source": [
    "# encode the training dataset in the form of sentences pair\n",
    "# truncate at length=64 for a balance of time consuming and information coverage\n",
    "encoded_train = train.map(lambda batch: tokenizer(batch['questions']['text'][0], batch['questions']['text'][1], \n",
    "                                                  padding='max_length', truncation=True, max_length=64))\n",
    "encoded_train.rename_column_(\"is_duplicate\", \"labels\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at C:\\Users\\52673\\.cache\\huggingface\\datasets\\quora\\default\\0.0.0\\36ba4cd42107f051a158016f1bea6ae3f4685c5df843529108a54e42d86c1e04\\cache-f8a88f1864b30ad1.arrow\n"
     ]
    }
   ],
   "source": [
    "# encode the validation dataset in the form of sentences pair\n",
    "encoded_validation = validation.map(lambda batch: tokenizer(batch['questions']['text'][0], batch['questions']['text'][1], \n",
    "                                                            padding='max_length', truncation=True, max_length=64))\n",
    "encoded_validation.rename_column_(\"is_duplicate\", \"labels\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_train.set_format(\"torch\", columns=[\"input_ids\", \"token_type_ids\", \"attention_mask\", \"labels\"])\n",
    "encoded_validation.set_format(\"torch\", columns=[\"input_ids\", \"token_type_ids\", \"attention_mask\", \"labels\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'labels': torch.Size([]), 'input_ids': torch.Size([64]), 'token_type_ids': torch.Size([64]), 'attention_mask': torch.Size([64])}\n",
      "{'labels': torch.Size([]), 'input_ids': torch.Size([64]), 'token_type_ids': torch.Size([64]), 'attention_mask': torch.Size([64])}\n"
     ]
    }
   ],
   "source": [
    "# check if the format is valid, and if each tensor have the same size\n",
    "print({key: val.shape for key, val in encoded_validation[0].items()})\n",
    "print({key: val.shape for key, val in encoded_validation[1].items()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'labels': tensor(0),\n",
       " 'input_ids': tensor([  101,  2054,  2003,  1996,  2466,  1997, 12849, 10606, 16506,  1006,\n",
       "         12849,  2232,  1011,  1045,  1011,  2053,  2953,  1007,  6323,  1029,\n",
       "           102,  2054,  2052,  4148,  2065,  1996,  2796,  2231, 10312,  1996,\n",
       "         12849, 10606, 16506,  1006, 12849,  2232,  1011,  1045,  1011,  2053,\n",
       "          2953,  1007,  6323,  2067,  1029,   102,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0]),\n",
       " 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# take a look at an encoded sample\n",
    "encoded_train[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine-tune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# another way to load pretrained weights\n",
    "output_config_file = \"./config.json\"\n",
    "output_model_file = \"./sup-simcse.bin\"\n",
    "\n",
    "config = BertConfig.from_json_file(output_config_file)\n",
    "model = BertModel(config = config)\n",
    "state_dict = torch.load(output_model_file)\n",
    "model.load_state_dict(state_dict)\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at princeton-nlp/sup-simcse-bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# load pretrained weights to initialize Bert\n",
    "# here we use the default config to control variates, so the only diff here will be the initial weights(pretrained with or w/o CL)\n",
    "model = BertForSequenceClassification.from_pretrained(\"princeton-nlp/sup-simcse-bert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean up gpu cache before training\n",
    "import gc\n",
    "\n",
    "gc.collect()\n",
    "\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the training set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: questions.\n",
      "***** Running training *****\n",
      "  Num examples = 141502\n",
      "  Num Epochs = 3\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 53064\n",
      "  1%|          | 500/53064 [01:44<3:16:35,  4.46it/s]Saving model checkpoint to tmp_trainer\\checkpoint-500\n",
      "Configuration saved in tmp_trainer\\checkpoint-500\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.531, 'learning_rate': 4.9528870797527514e-05, 'epoch': 0.03}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in tmp_trainer\\checkpoint-500\\pytorch_model.bin\n",
      "  2%|▏         | 1000/53064 [03:27<2:49:40,  5.11it/s]Saving model checkpoint to tmp_trainer\\checkpoint-1000\n",
      "Configuration saved in tmp_trainer\\checkpoint-1000\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.4601, 'learning_rate': 4.9057741595055026e-05, 'epoch': 0.06}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in tmp_trainer\\checkpoint-1000\\pytorch_model.bin\n",
      "  3%|▎         | 1500/53064 [05:06<2:49:54,  5.06it/s]Saving model checkpoint to tmp_trainer\\checkpoint-1500\n",
      "Configuration saved in tmp_trainer\\checkpoint-1500\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.4491, 'learning_rate': 4.8586612392582545e-05, 'epoch': 0.08}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in tmp_trainer\\checkpoint-1500\\pytorch_model.bin\n",
      "  4%|▍         | 2000/53064 [06:48<3:04:38,  4.61it/s]Saving model checkpoint to tmp_trainer\\checkpoint-2000\n",
      "Configuration saved in tmp_trainer\\checkpoint-2000\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.4297, 'learning_rate': 4.811548319011006e-05, 'epoch': 0.11}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in tmp_trainer\\checkpoint-2000\\pytorch_model.bin\n",
      "  5%|▍         | 2500/53064 [08:36<2:48:40,  5.00it/s]Saving model checkpoint to tmp_trainer\\checkpoint-2500\n",
      "Configuration saved in tmp_trainer\\checkpoint-2500\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.4248, 'learning_rate': 4.7644353987637576e-05, 'epoch': 0.14}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in tmp_trainer\\checkpoint-2500\\pytorch_model.bin\n",
      "  6%|▌         | 3000/53064 [10:21<2:56:48,  4.72it/s]Saving model checkpoint to tmp_trainer\\checkpoint-3000\n",
      "Configuration saved in tmp_trainer\\checkpoint-3000\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.4281, 'learning_rate': 4.717322478516509e-05, 'epoch': 0.17}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in tmp_trainer\\checkpoint-3000\\pytorch_model.bin\n",
      "  7%|▋         | 3500/53064 [12:07<2:53:45,  4.75it/s]Saving model checkpoint to tmp_trainer\\checkpoint-3500\n",
      "Configuration saved in tmp_trainer\\checkpoint-3500\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.4166, 'learning_rate': 4.67020955826926e-05, 'epoch': 0.2}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in tmp_trainer\\checkpoint-3500\\pytorch_model.bin\n",
      "  8%|▊         | 4000/53064 [13:51<2:42:50,  5.02it/s]Saving model checkpoint to tmp_trainer\\checkpoint-4000\n",
      "Configuration saved in tmp_trainer\\checkpoint-4000\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.4043, 'learning_rate': 4.623096638022011e-05, 'epoch': 0.23}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in tmp_trainer\\checkpoint-4000\\pytorch_model.bin\n",
      "  8%|▊         | 4500/53064 [15:35<2:37:44,  5.13it/s]Saving model checkpoint to tmp_trainer\\checkpoint-4500\n",
      "Configuration saved in tmp_trainer\\checkpoint-4500\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.4153, 'learning_rate': 4.575983717774763e-05, 'epoch': 0.25}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in tmp_trainer\\checkpoint-4500\\pytorch_model.bin\n",
      "  9%|▉         | 5000/53064 [17:18<2:56:27,  4.54it/s]Saving model checkpoint to tmp_trainer\\checkpoint-5000\n",
      "Configuration saved in tmp_trainer\\checkpoint-5000\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.4026, 'learning_rate': 4.528870797527514e-05, 'epoch': 0.28}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in tmp_trainer\\checkpoint-5000\\pytorch_model.bin\n",
      " 10%|█         | 5500/53064 [19:01<2:36:35,  5.06it/s]Saving model checkpoint to tmp_trainer\\checkpoint-5500\n",
      "Configuration saved in tmp_trainer\\checkpoint-5500\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.4068, 'learning_rate': 4.4817578772802655e-05, 'epoch': 0.31}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in tmp_trainer\\checkpoint-5500\\pytorch_model.bin\n",
      " 11%|█▏        | 6000/53064 [20:46<2:35:01,  5.06it/s]Saving model checkpoint to tmp_trainer\\checkpoint-6000\n",
      "Configuration saved in tmp_trainer\\checkpoint-6000\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.4015, 'learning_rate': 4.434644957033017e-05, 'epoch': 0.34}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in tmp_trainer\\checkpoint-6000\\pytorch_model.bin\n",
      " 12%|█▏        | 6500/53064 [22:26<2:31:22,  5.13it/s]Saving model checkpoint to tmp_trainer\\checkpoint-6500\n",
      "Configuration saved in tmp_trainer\\checkpoint-6500\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.4103, 'learning_rate': 4.387532036785768e-05, 'epoch': 0.37}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in tmp_trainer\\checkpoint-6500\\pytorch_model.bin\n",
      " 13%|█▎        | 7000/53064 [24:06<2:29:28,  5.14it/s]Saving model checkpoint to tmp_trainer\\checkpoint-7000\n",
      "Configuration saved in tmp_trainer\\checkpoint-7000\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3945, 'learning_rate': 4.34041911653852e-05, 'epoch': 0.4}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in tmp_trainer\\checkpoint-7000\\pytorch_model.bin\n",
      " 14%|█▍        | 7500/53064 [25:46<2:28:51,  5.10it/s]Saving model checkpoint to tmp_trainer\\checkpoint-7500\n",
      "Configuration saved in tmp_trainer\\checkpoint-7500\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3955, 'learning_rate': 4.293306196291271e-05, 'epoch': 0.42}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in tmp_trainer\\checkpoint-7500\\pytorch_model.bin\n",
      " 15%|█▌        | 8000/53064 [27:27<2:26:51,  5.11it/s]Saving model checkpoint to tmp_trainer\\checkpoint-8000\n",
      "Configuration saved in tmp_trainer\\checkpoint-8000\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3944, 'learning_rate': 4.246193276044023e-05, 'epoch': 0.45}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in tmp_trainer\\checkpoint-8000\\pytorch_model.bin\n",
      " 16%|█▌        | 8500/53064 [29:07<2:26:41,  5.06it/s]Saving model checkpoint to tmp_trainer\\checkpoint-8500\n",
      "Configuration saved in tmp_trainer\\checkpoint-8500\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3885, 'learning_rate': 4.199080355796774e-05, 'epoch': 0.48}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in tmp_trainer\\checkpoint-8500\\pytorch_model.bin\n",
      " 17%|█▋        | 9000/53064 [30:47<2:24:29,  5.08it/s]Saving model checkpoint to tmp_trainer\\checkpoint-9000\n",
      "Configuration saved in tmp_trainer\\checkpoint-9000\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3913, 'learning_rate': 4.151967435549525e-05, 'epoch': 0.51}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in tmp_trainer\\checkpoint-9000\\pytorch_model.bin\n",
      " 18%|█▊        | 9500/53064 [32:27<2:22:46,  5.09it/s]Saving model checkpoint to tmp_trainer\\checkpoint-9500\n",
      "Configuration saved in tmp_trainer\\checkpoint-9500\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3834, 'learning_rate': 4.1048545153022765e-05, 'epoch': 0.54}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in tmp_trainer\\checkpoint-9500\\pytorch_model.bin\n",
      " 19%|█▉        | 10000/53064 [34:07<2:19:37,  5.14it/s]Saving model checkpoint to tmp_trainer\\checkpoint-10000\n",
      "Configuration saved in tmp_trainer\\checkpoint-10000\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3669, 'learning_rate': 4.057741595055028e-05, 'epoch': 0.57}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in tmp_trainer\\checkpoint-10000\\pytorch_model.bin\n",
      " 20%|█▉        | 10500/53064 [35:47<2:19:33,  5.08it/s]Saving model checkpoint to tmp_trainer\\checkpoint-10500\n",
      "Configuration saved in tmp_trainer\\checkpoint-10500\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3999, 'learning_rate': 4.0106286748077796e-05, 'epoch': 0.59}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in tmp_trainer\\checkpoint-10500\\pytorch_model.bin\n",
      " 21%|██        | 11000/53064 [37:27<2:16:16,  5.14it/s]Saving model checkpoint to tmp_trainer\\checkpoint-11000\n",
      "Configuration saved in tmp_trainer\\checkpoint-11000\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3603, 'learning_rate': 3.9635157545605314e-05, 'epoch': 0.62}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in tmp_trainer\\checkpoint-11000\\pytorch_model.bin\n",
      " 22%|██▏       | 11500/53064 [39:07<2:14:46,  5.14it/s]Saving model checkpoint to tmp_trainer\\checkpoint-11500\n",
      "Configuration saved in tmp_trainer\\checkpoint-11500\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3817, 'learning_rate': 3.9164028343132826e-05, 'epoch': 0.65}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in tmp_trainer\\checkpoint-11500\\pytorch_model.bin\n",
      " 23%|██▎       | 12000/53064 [40:47<2:12:36,  5.16it/s]Saving model checkpoint to tmp_trainer\\checkpoint-12000\n",
      "Configuration saved in tmp_trainer\\checkpoint-12000\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3645, 'learning_rate': 3.869289914066034e-05, 'epoch': 0.68}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in tmp_trainer\\checkpoint-12000\\pytorch_model.bin\n",
      " 24%|██▎       | 12500/53064 [42:26<2:08:55,  5.24it/s]Saving model checkpoint to tmp_trainer\\checkpoint-12500\n",
      "Configuration saved in tmp_trainer\\checkpoint-12500\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3825, 'learning_rate': 3.822176993818785e-05, 'epoch': 0.71}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in tmp_trainer\\checkpoint-12500\\pytorch_model.bin\n",
      " 24%|██▍       | 13000/53064 [44:05<2:09:46,  5.15it/s]Saving model checkpoint to tmp_trainer\\checkpoint-13000\n",
      "Configuration saved in tmp_trainer\\checkpoint-13000\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3767, 'learning_rate': 3.775064073571536e-05, 'epoch': 0.73}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in tmp_trainer\\checkpoint-13000\\pytorch_model.bin\n",
      " 25%|██▌       | 13500/53064 [45:44<2:07:32,  5.17it/s]Saving model checkpoint to tmp_trainer\\checkpoint-13500\n",
      "Configuration saved in tmp_trainer\\checkpoint-13500\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3684, 'learning_rate': 3.727951153324288e-05, 'epoch': 0.76}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in tmp_trainer\\checkpoint-13500\\pytorch_model.bin\n",
      " 26%|██▋       | 14000/53064 [47:24<2:07:38,  5.10it/s]Saving model checkpoint to tmp_trainer\\checkpoint-14000\n",
      "Configuration saved in tmp_trainer\\checkpoint-14000\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.361, 'learning_rate': 3.680838233077039e-05, 'epoch': 0.79}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in tmp_trainer\\checkpoint-14000\\pytorch_model.bin\n",
      " 27%|██▋       | 14500/53064 [49:04<2:04:41,  5.15it/s]Saving model checkpoint to tmp_trainer\\checkpoint-14500\n",
      "Configuration saved in tmp_trainer\\checkpoint-14500\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3738, 'learning_rate': 3.6337253128297905e-05, 'epoch': 0.82}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in tmp_trainer\\checkpoint-14500\\pytorch_model.bin\n",
      " 28%|██▊       | 15000/53064 [50:43<2:00:26,  5.27it/s]Saving model checkpoint to tmp_trainer\\checkpoint-15000\n",
      "Configuration saved in tmp_trainer\\checkpoint-15000\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3708, 'learning_rate': 3.586612392582542e-05, 'epoch': 0.85}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in tmp_trainer\\checkpoint-15000\\pytorch_model.bin\n",
      " 29%|██▉       | 15500/53064 [52:20<1:59:14,  5.25it/s]Saving model checkpoint to tmp_trainer\\checkpoint-15500\n",
      "Configuration saved in tmp_trainer\\checkpoint-15500\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3628, 'learning_rate': 3.5394994723352936e-05, 'epoch': 0.88}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in tmp_trainer\\checkpoint-15500\\pytorch_model.bin\n",
      " 30%|███       | 16000/53064 [53:57<2:00:00,  5.15it/s]Saving model checkpoint to tmp_trainer\\checkpoint-16000\n",
      "Configuration saved in tmp_trainer\\checkpoint-16000\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3505, 'learning_rate': 3.492386552088045e-05, 'epoch': 0.9}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in tmp_trainer\\checkpoint-16000\\pytorch_model.bin\n",
      " 31%|███       | 16500/53064 [55:34<1:56:00,  5.25it/s]Saving model checkpoint to tmp_trainer\\checkpoint-16500\n",
      "Configuration saved in tmp_trainer\\checkpoint-16500\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3667, 'learning_rate': 3.445273631840796e-05, 'epoch': 0.93}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in tmp_trainer\\checkpoint-16500\\pytorch_model.bin\n",
      " 32%|███▏      | 17000/53064 [57:12<1:53:59,  5.27it/s]Saving model checkpoint to tmp_trainer\\checkpoint-17000\n",
      "Configuration saved in tmp_trainer\\checkpoint-17000\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3666, 'learning_rate': 3.398160711593548e-05, 'epoch': 0.96}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in tmp_trainer\\checkpoint-17000\\pytorch_model.bin\n",
      " 33%|███▎      | 17500/53064 [58:51<1:53:50,  5.21it/s]Saving model checkpoint to tmp_trainer\\checkpoint-17500\n",
      "Configuration saved in tmp_trainer\\checkpoint-17500\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3577, 'learning_rate': 3.351047791346299e-05, 'epoch': 0.99}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in tmp_trainer\\checkpoint-17500\\pytorch_model.bin\n",
      " 34%|███▍      | 18000/53064 [1:00:29<1:51:55,  5.22it/s]Saving model checkpoint to tmp_trainer\\checkpoint-18000\n",
      "Configuration saved in tmp_trainer\\checkpoint-18000\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3219, 'learning_rate': 3.30393487109905e-05, 'epoch': 1.02}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in tmp_trainer\\checkpoint-18000\\pytorch_model.bin\n",
      " 35%|███▍      | 18500/53064 [1:02:07<1:48:12,  5.32it/s]Saving model checkpoint to tmp_trainer\\checkpoint-18500\n",
      "Configuration saved in tmp_trainer\\checkpoint-18500\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3063, 'learning_rate': 3.2568219508518015e-05, 'epoch': 1.05}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in tmp_trainer\\checkpoint-18500\\pytorch_model.bin\n",
      " 36%|███▌      | 19000/53064 [1:03:44<1:48:23,  5.24it/s]Saving model checkpoint to tmp_trainer\\checkpoint-19000\n",
      "Configuration saved in tmp_trainer\\checkpoint-19000\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.319, 'learning_rate': 3.209709030604553e-05, 'epoch': 1.07}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in tmp_trainer\\checkpoint-19000\\pytorch_model.bin\n",
      " 37%|███▋      | 19500/53064 [1:05:21<1:46:32,  5.25it/s]Saving model checkpoint to tmp_trainer\\checkpoint-19500\n",
      "Configuration saved in tmp_trainer\\checkpoint-19500\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2979, 'learning_rate': 3.1625961103573046e-05, 'epoch': 1.1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in tmp_trainer\\checkpoint-19500\\pytorch_model.bin\n",
      " 38%|███▊      | 20000/53064 [1:06:57<1:40:54,  5.46it/s]Saving model checkpoint to tmp_trainer\\checkpoint-20000\n",
      "Configuration saved in tmp_trainer\\checkpoint-20000\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3227, 'learning_rate': 3.1154831901100565e-05, 'epoch': 1.13}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in tmp_trainer\\checkpoint-20000\\pytorch_model.bin\n",
      " 39%|███▊      | 20500/53064 [1:08:33<1:42:11,  5.31it/s]Saving model checkpoint to tmp_trainer\\checkpoint-20500\n",
      "Configuration saved in tmp_trainer\\checkpoint-20500\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3216, 'learning_rate': 3.068370269862808e-05, 'epoch': 1.16}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in tmp_trainer\\checkpoint-20500\\pytorch_model.bin\n",
      " 40%|███▉      | 21000/53064 [1:10:09<1:39:50,  5.35it/s]Saving model checkpoint to tmp_trainer\\checkpoint-21000\n",
      "Configuration saved in tmp_trainer\\checkpoint-21000\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3077, 'learning_rate': 3.021257349615559e-05, 'epoch': 1.19}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in tmp_trainer\\checkpoint-21000\\pytorch_model.bin\n",
      " 41%|████      | 21500/53064 [1:11:46<1:41:07,  5.20it/s]Saving model checkpoint to tmp_trainer\\checkpoint-21500\n",
      "Configuration saved in tmp_trainer\\checkpoint-21500\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3684, 'learning_rate': 2.97414442936831e-05, 'epoch': 1.22}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in tmp_trainer\\checkpoint-21500\\pytorch_model.bin\n",
      " 41%|████▏     | 22000/53064 [1:13:24<1:37:00,  5.34it/s]Saving model checkpoint to tmp_trainer\\checkpoint-22000\n",
      "Configuration saved in tmp_trainer\\checkpoint-22000\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3099, 'learning_rate': 2.9270315091210616e-05, 'epoch': 1.24}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in tmp_trainer\\checkpoint-22000\\pytorch_model.bin\n",
      " 42%|████▏     | 22500/53064 [1:15:02<1:38:43,  5.16it/s]Saving model checkpoint to tmp_trainer\\checkpoint-22500\n",
      "Configuration saved in tmp_trainer\\checkpoint-22500\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3231, 'learning_rate': 2.8799185888738128e-05, 'epoch': 1.27}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in tmp_trainer\\checkpoint-22500\\pytorch_model.bin\n",
      " 43%|████▎     | 23000/53064 [1:16:40<1:35:10,  5.26it/s]Saving model checkpoint to tmp_trainer\\checkpoint-23000\n",
      "Configuration saved in tmp_trainer\\checkpoint-23000\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3141, 'learning_rate': 2.832805668626564e-05, 'epoch': 1.3}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in tmp_trainer\\checkpoint-23000\\pytorch_model.bin\n",
      " 44%|████▍     | 23500/53064 [1:18:16<1:33:01,  5.30it/s]Saving model checkpoint to tmp_trainer\\checkpoint-23500\n",
      "Configuration saved in tmp_trainer\\checkpoint-23500\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.305, 'learning_rate': 2.7856927483793156e-05, 'epoch': 1.33}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in tmp_trainer\\checkpoint-23500\\pytorch_model.bin\n",
      " 45%|████▌     | 24000/53064 [1:19:52<1:31:22,  5.30it/s]Saving model checkpoint to tmp_trainer\\checkpoint-24000\n",
      "Configuration saved in tmp_trainer\\checkpoint-24000\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3247, 'learning_rate': 2.7385798281320668e-05, 'epoch': 1.36}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in tmp_trainer\\checkpoint-24000\\pytorch_model.bin\n",
      " 46%|████▌     | 24500/53064 [1:21:28<1:31:16,  5.22it/s]Saving model checkpoint to tmp_trainer\\checkpoint-24500\n",
      "Configuration saved in tmp_trainer\\checkpoint-24500\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3297, 'learning_rate': 2.6914669078848186e-05, 'epoch': 1.39}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in tmp_trainer\\checkpoint-24500\\pytorch_model.bin\n",
      " 47%|████▋     | 25000/53064 [1:23:05<1:28:35,  5.28it/s]Saving model checkpoint to tmp_trainer\\checkpoint-25000\n",
      "Configuration saved in tmp_trainer\\checkpoint-25000\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3381, 'learning_rate': 2.6443539876375702e-05, 'epoch': 1.41}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in tmp_trainer\\checkpoint-25000\\pytorch_model.bin\n",
      " 48%|████▊     | 25500/53064 [1:24:41<1:27:02,  5.28it/s]Saving model checkpoint to tmp_trainer\\checkpoint-25500\n",
      "Configuration saved in tmp_trainer\\checkpoint-25500\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3368, 'learning_rate': 2.5972410673903214e-05, 'epoch': 1.44}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in tmp_trainer\\checkpoint-25500\\pytorch_model.bin\n",
      " 49%|████▉     | 26000/53064 [1:26:19<1:26:27,  5.22it/s]Saving model checkpoint to tmp_trainer\\checkpoint-26000\n",
      "Configuration saved in tmp_trainer\\checkpoint-26000\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3256, 'learning_rate': 2.5501281471430726e-05, 'epoch': 1.47}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in tmp_trainer\\checkpoint-26000\\pytorch_model.bin\n",
      " 50%|████▉     | 26500/53064 [1:28:01<1:25:38,  5.17it/s]Saving model checkpoint to tmp_trainer\\checkpoint-26500\n",
      "Configuration saved in tmp_trainer\\checkpoint-26500\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3071, 'learning_rate': 2.503015226895824e-05, 'epoch': 1.5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in tmp_trainer\\checkpoint-26500\\pytorch_model.bin\n",
      " 51%|█████     | 27000/53064 [1:29:44<1:32:10,  4.71it/s]Saving model checkpoint to tmp_trainer\\checkpoint-27000\n",
      "Configuration saved in tmp_trainer\\checkpoint-27000\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3034, 'learning_rate': 2.4559023066485753e-05, 'epoch': 1.53}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in tmp_trainer\\checkpoint-27000\\pytorch_model.bin\n",
      " 52%|█████▏    | 27500/53064 [1:31:29<1:28:50,  4.80it/s]Saving model checkpoint to tmp_trainer\\checkpoint-27500\n",
      "Configuration saved in tmp_trainer\\checkpoint-27500\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3118, 'learning_rate': 2.408789386401327e-05, 'epoch': 1.55}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in tmp_trainer\\checkpoint-27500\\pytorch_model.bin\n",
      " 53%|█████▎    | 28000/53064 [1:33:09<1:21:28,  5.13it/s]Saving model checkpoint to tmp_trainer\\checkpoint-28000\n",
      "Configuration saved in tmp_trainer\\checkpoint-28000\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3224, 'learning_rate': 2.3616764661540784e-05, 'epoch': 1.58}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in tmp_trainer\\checkpoint-28000\\pytorch_model.bin\n",
      " 54%|█████▎    | 28500/53064 [1:34:52<1:22:15,  4.98it/s]Saving model checkpoint to tmp_trainer\\checkpoint-28500\n",
      "Configuration saved in tmp_trainer\\checkpoint-28500\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3269, 'learning_rate': 2.3145635459068296e-05, 'epoch': 1.61}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in tmp_trainer\\checkpoint-28500\\pytorch_model.bin\n",
      " 55%|█████▍    | 29000/53064 [1:36:34<1:18:29,  5.11it/s]Saving model checkpoint to tmp_trainer\\checkpoint-29000\n",
      "Configuration saved in tmp_trainer\\checkpoint-29000\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3138, 'learning_rate': 2.2674506256595808e-05, 'epoch': 1.64}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in tmp_trainer\\checkpoint-29000\\pytorch_model.bin\n",
      " 56%|█████▌    | 29500/53064 [1:38:17<1:18:41,  4.99it/s]Saving model checkpoint to tmp_trainer\\checkpoint-29500\n",
      "Configuration saved in tmp_trainer\\checkpoint-29500\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3164, 'learning_rate': 2.2203377054123324e-05, 'epoch': 1.67}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in tmp_trainer\\checkpoint-29500\\pytorch_model.bin\n",
      " 57%|█████▋    | 30000/53064 [1:39:57<1:13:45,  5.21it/s]Saving model checkpoint to tmp_trainer\\checkpoint-30000\n",
      "Configuration saved in tmp_trainer\\checkpoint-30000\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3026, 'learning_rate': 2.173224785165084e-05, 'epoch': 1.7}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in tmp_trainer\\checkpoint-30000\\pytorch_model.bin\n",
      " 57%|█████▋    | 30500/53064 [1:41:37<1:13:00,  5.15it/s]Saving model checkpoint to tmp_trainer\\checkpoint-30500\n",
      "Configuration saved in tmp_trainer\\checkpoint-30500\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3252, 'learning_rate': 2.126111864917835e-05, 'epoch': 1.72}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in tmp_trainer\\checkpoint-30500\\pytorch_model.bin\n",
      " 58%|█████▊    | 31000/53064 [1:43:18<1:12:00,  5.11it/s]Saving model checkpoint to tmp_trainer\\checkpoint-31000\n",
      "Configuration saved in tmp_trainer\\checkpoint-31000\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3161, 'learning_rate': 2.0789989446705866e-05, 'epoch': 1.75}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in tmp_trainer\\checkpoint-31000\\pytorch_model.bin\n",
      " 59%|█████▉    | 31500/53064 [1:44:58<1:10:11,  5.12it/s]Saving model checkpoint to tmp_trainer\\checkpoint-31500\n",
      "Configuration saved in tmp_trainer\\checkpoint-31500\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3247, 'learning_rate': 2.031886024423338e-05, 'epoch': 1.78}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in tmp_trainer\\checkpoint-31500\\pytorch_model.bin\n",
      " 60%|██████    | 32000/53064 [1:46:40<1:11:28,  4.91it/s]Saving model checkpoint to tmp_trainer\\checkpoint-32000\n",
      "Configuration saved in tmp_trainer\\checkpoint-32000\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3045, 'learning_rate': 1.9847731041760894e-05, 'epoch': 1.81}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in tmp_trainer\\checkpoint-32000\\pytorch_model.bin\n",
      " 61%|██████    | 32500/53064 [1:48:22<1:07:43,  5.06it/s]Saving model checkpoint to tmp_trainer\\checkpoint-32500\n",
      "Configuration saved in tmp_trainer\\checkpoint-32500\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3186, 'learning_rate': 1.937660183928841e-05, 'epoch': 1.84}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in tmp_trainer\\checkpoint-32500\\pytorch_model.bin\n",
      " 62%|██████▏   | 33000/53064 [1:50:05<1:04:05,  5.22it/s]Saving model checkpoint to tmp_trainer\\checkpoint-33000\n",
      "Configuration saved in tmp_trainer\\checkpoint-33000\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3165, 'learning_rate': 1.890547263681592e-05, 'epoch': 1.87}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in tmp_trainer\\checkpoint-33000\\pytorch_model.bin\n",
      " 63%|██████▎   | 33500/53064 [1:51:46<1:05:26,  4.98it/s]Saving model checkpoint to tmp_trainer\\checkpoint-33500\n",
      "Configuration saved in tmp_trainer\\checkpoint-33500\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2888, 'learning_rate': 1.8434343434343433e-05, 'epoch': 1.89}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in tmp_trainer\\checkpoint-33500\\pytorch_model.bin\n",
      " 64%|██████▍   | 34000/53064 [1:53:26<1:02:12,  5.11it/s]Saving model checkpoint to tmp_trainer\\checkpoint-34000\n",
      "Configuration saved in tmp_trainer\\checkpoint-34000\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3103, 'learning_rate': 1.796321423187095e-05, 'epoch': 1.92}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in tmp_trainer\\checkpoint-34000\\pytorch_model.bin\n",
      " 65%|██████▌   | 34500/53064 [1:55:05<59:01,  5.24it/s]Saving model checkpoint to tmp_trainer\\checkpoint-34500\n",
      "Configuration saved in tmp_trainer\\checkpoint-34500\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2993, 'learning_rate': 1.7492085029398464e-05, 'epoch': 1.95}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in tmp_trainer\\checkpoint-34500\\pytorch_model.bin\n",
      " 66%|██████▌   | 35000/53064 [1:56:46<59:36,  5.05it/s]Saving model checkpoint to tmp_trainer\\checkpoint-35000\n",
      "Configuration saved in tmp_trainer\\checkpoint-35000\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2986, 'learning_rate': 1.7020955826925976e-05, 'epoch': 1.98}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in tmp_trainer\\checkpoint-35000\\pytorch_model.bin\n",
      " 67%|██████▋   | 35500/53064 [1:58:27<1:03:20,  4.62it/s]Saving model checkpoint to tmp_trainer\\checkpoint-35500\n",
      "Configuration saved in tmp_trainer\\checkpoint-35500\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.28, 'learning_rate': 1.654982662445349e-05, 'epoch': 2.01}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in tmp_trainer\\checkpoint-35500\\pytorch_model.bin\n",
      " 68%|██████▊   | 36000/53064 [2:00:09<54:49,  5.19it/s]Saving model checkpoint to tmp_trainer\\checkpoint-36000\n",
      "Configuration saved in tmp_trainer\\checkpoint-36000\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2434, 'learning_rate': 1.6078697421981004e-05, 'epoch': 2.04}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in tmp_trainer\\checkpoint-36000\\pytorch_model.bin\n",
      " 69%|██████▉   | 36500/53064 [2:01:50<51:35,  5.35it/s]Saving model checkpoint to tmp_trainer\\checkpoint-36500\n",
      "Configuration saved in tmp_trainer\\checkpoint-36500\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2382, 'learning_rate': 1.560756821950852e-05, 'epoch': 2.06}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in tmp_trainer\\checkpoint-36500\\pytorch_model.bin\n",
      " 70%|██████▉   | 37000/53064 [2:03:29<50:56,  5.26it/s]Saving model checkpoint to tmp_trainer\\checkpoint-37000\n",
      "Configuration saved in tmp_trainer\\checkpoint-37000\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2371, 'learning_rate': 1.5136439017036033e-05, 'epoch': 2.09}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in tmp_trainer\\checkpoint-37000\\pytorch_model.bin\n",
      " 71%|███████   | 37500/53064 [2:05:07<48:06,  5.39it/s]Saving model checkpoint to tmp_trainer\\checkpoint-37500\n",
      "Configuration saved in tmp_trainer\\checkpoint-37500\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2411, 'learning_rate': 1.4665309814563547e-05, 'epoch': 2.12}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in tmp_trainer\\checkpoint-37500\\pytorch_model.bin\n",
      " 72%|███████▏  | 38000/53064 [2:06:43<46:35,  5.39it/s]Saving model checkpoint to tmp_trainer\\checkpoint-38000\n",
      "Configuration saved in tmp_trainer\\checkpoint-38000\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2404, 'learning_rate': 1.419418061209106e-05, 'epoch': 2.15}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in tmp_trainer\\checkpoint-38000\\pytorch_model.bin\n",
      " 73%|███████▎  | 38500/53064 [2:08:21<46:38,  5.20it/s]Saving model checkpoint to tmp_trainer\\checkpoint-38500\n",
      "Configuration saved in tmp_trainer\\checkpoint-38500\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2411, 'learning_rate': 1.3723051409618576e-05, 'epoch': 2.18}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in tmp_trainer\\checkpoint-38500\\pytorch_model.bin\n",
      " 73%|███████▎  | 39000/53064 [2:09:59<44:51,  5.23it/s]Saving model checkpoint to tmp_trainer\\checkpoint-39000\n",
      "Configuration saved in tmp_trainer\\checkpoint-39000\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2266, 'learning_rate': 1.325192220714609e-05, 'epoch': 2.2}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in tmp_trainer\\checkpoint-39000\\pytorch_model.bin\n",
      " 74%|███████▍  | 39500/53064 [2:11:36<42:35,  5.31it/s]Saving model checkpoint to tmp_trainer\\checkpoint-39500\n",
      "Configuration saved in tmp_trainer\\checkpoint-39500\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.254, 'learning_rate': 1.2780793004673603e-05, 'epoch': 2.23}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in tmp_trainer\\checkpoint-39500\\pytorch_model.bin\n",
      " 75%|███████▌  | 40000/53064 [2:13:14<40:25,  5.39it/s]Saving model checkpoint to tmp_trainer\\checkpoint-40000\n",
      "Configuration saved in tmp_trainer\\checkpoint-40000\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2448, 'learning_rate': 1.2309663802201115e-05, 'epoch': 2.26}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in tmp_trainer\\checkpoint-40000\\pytorch_model.bin\n",
      " 76%|███████▋  | 40500/53064 [2:14:51<39:33,  5.29it/s]Saving model checkpoint to tmp_trainer\\checkpoint-40500\n",
      "Configuration saved in tmp_trainer\\checkpoint-40500\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2288, 'learning_rate': 1.183853459972863e-05, 'epoch': 2.29}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in tmp_trainer\\checkpoint-40500\\pytorch_model.bin\n",
      " 77%|███████▋  | 41000/53064 [2:16:28<37:21,  5.38it/s]Saving model checkpoint to tmp_trainer\\checkpoint-41000\n",
      "Configuration saved in tmp_trainer\\checkpoint-41000\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2329, 'learning_rate': 1.1367405397256144e-05, 'epoch': 2.32}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in tmp_trainer\\checkpoint-41000\\pytorch_model.bin\n",
      " 78%|███████▊  | 41500/53064 [2:18:04<35:03,  5.50it/s]Saving model checkpoint to tmp_trainer\\checkpoint-41500\n",
      "Configuration saved in tmp_trainer\\checkpoint-41500\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2279, 'learning_rate': 1.0896276194783658e-05, 'epoch': 2.35}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in tmp_trainer\\checkpoint-41500\\pytorch_model.bin\n",
      " 79%|███████▉  | 42000/53064 [2:19:41<35:17,  5.22it/s]Saving model checkpoint to tmp_trainer\\checkpoint-42000\n",
      "Configuration saved in tmp_trainer\\checkpoint-42000\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2427, 'learning_rate': 1.0425146992311172e-05, 'epoch': 2.37}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in tmp_trainer\\checkpoint-42000\\pytorch_model.bin\n",
      " 80%|████████  | 42500/53064 [2:21:19<34:35,  5.09it/s]Saving model checkpoint to tmp_trainer\\checkpoint-42500\n",
      "Configuration saved in tmp_trainer\\checkpoint-42500\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2408, 'learning_rate': 9.954017789838687e-06, 'epoch': 2.4}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in tmp_trainer\\checkpoint-42500\\pytorch_model.bin\n",
      " 81%|████████  | 43000/53064 [2:22:55<31:20,  5.35it/s]Saving model checkpoint to tmp_trainer\\checkpoint-43000\n",
      "Configuration saved in tmp_trainer\\checkpoint-43000\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2218, 'learning_rate': 9.482888587366199e-06, 'epoch': 2.43}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in tmp_trainer\\checkpoint-43000\\pytorch_model.bin\n",
      " 82%|████████▏ | 43500/53064 [2:24:31<32:20,  4.93it/s]Saving model checkpoint to tmp_trainer\\checkpoint-43500\n",
      "Configuration saved in tmp_trainer\\checkpoint-43500\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2306, 'learning_rate': 9.011759384893715e-06, 'epoch': 2.46}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in tmp_trainer\\checkpoint-43500\\pytorch_model.bin\n",
      " 83%|████████▎ | 44000/53064 [2:26:07<28:50,  5.24it/s]Saving model checkpoint to tmp_trainer\\checkpoint-44000\n",
      "Configuration saved in tmp_trainer\\checkpoint-44000\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.232, 'learning_rate': 8.540630182421228e-06, 'epoch': 2.49}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in tmp_trainer\\checkpoint-44000\\pytorch_model.bin\n",
      " 84%|████████▍ | 44500/53064 [2:27:43<26:54,  5.31it/s]Saving model checkpoint to tmp_trainer\\checkpoint-44500\n",
      "Configuration saved in tmp_trainer\\checkpoint-44500\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2375, 'learning_rate': 8.06950097994874e-06, 'epoch': 2.52}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in tmp_trainer\\checkpoint-44500\\pytorch_model.bin\n",
      " 85%|████████▍ | 45000/53064 [2:29:19<25:04,  5.36it/s]Saving model checkpoint to tmp_trainer\\checkpoint-45000\n",
      "Configuration saved in tmp_trainer\\checkpoint-45000\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2336, 'learning_rate': 7.598371777476256e-06, 'epoch': 2.54}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in tmp_trainer\\checkpoint-45000\\pytorch_model.bin\n",
      " 86%|████████▌ | 45500/53064 [2:30:55<23:07,  5.45it/s]Saving model checkpoint to tmp_trainer\\checkpoint-45500\n",
      "Configuration saved in tmp_trainer\\checkpoint-45500\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2294, 'learning_rate': 7.1272425750037685e-06, 'epoch': 2.57}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in tmp_trainer\\checkpoint-45500\\pytorch_model.bin\n",
      " 87%|████████▋ | 46000/53064 [2:32:32<22:32,  5.22it/s]Saving model checkpoint to tmp_trainer\\checkpoint-46000\n",
      "Configuration saved in tmp_trainer\\checkpoint-46000\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2361, 'learning_rate': 6.656113372531283e-06, 'epoch': 2.6}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in tmp_trainer\\checkpoint-46000\\pytorch_model.bin\n",
      " 88%|████████▊ | 46500/53064 [2:34:09<20:24,  5.36it/s]Saving model checkpoint to tmp_trainer\\checkpoint-46500\n",
      "Configuration saved in tmp_trainer\\checkpoint-46500\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2235, 'learning_rate': 6.184984170058798e-06, 'epoch': 2.63}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in tmp_trainer\\checkpoint-46500\\pytorch_model.bin\n",
      " 89%|████████▊ | 47000/53064 [2:35:45<19:17,  5.24it/s]Saving model checkpoint to tmp_trainer\\checkpoint-47000\n",
      "Configuration saved in tmp_trainer\\checkpoint-47000\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2106, 'learning_rate': 5.7138549675863105e-06, 'epoch': 2.66}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in tmp_trainer\\checkpoint-47000\\pytorch_model.bin\n",
      " 90%|████████▉ | 47500/53064 [2:37:22<17:44,  5.23it/s]Saving model checkpoint to tmp_trainer\\checkpoint-47500\n",
      "Configuration saved in tmp_trainer\\checkpoint-47500\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2511, 'learning_rate': 5.242725765113825e-06, 'epoch': 2.69}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in tmp_trainer\\checkpoint-47500\\pytorch_model.bin\n",
      " 90%|█████████ | 48000/53064 [2:38:59<16:15,  5.19it/s]Saving model checkpoint to tmp_trainer\\checkpoint-48000\n",
      "Configuration saved in tmp_trainer\\checkpoint-48000\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2334, 'learning_rate': 4.771596562641339e-06, 'epoch': 2.71}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in tmp_trainer\\checkpoint-48000\\pytorch_model.bin\n",
      " 91%|█████████▏| 48500/53064 [2:40:35<14:15,  5.33it/s]Saving model checkpoint to tmp_trainer\\checkpoint-48500\n",
      "Configuration saved in tmp_trainer\\checkpoint-48500\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2389, 'learning_rate': 4.3004673601688526e-06, 'epoch': 2.74}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in tmp_trainer\\checkpoint-48500\\pytorch_model.bin\n",
      " 92%|█████████▏| 49000/53064 [2:42:12<13:02,  5.19it/s]Saving model checkpoint to tmp_trainer\\checkpoint-49000\n",
      "Configuration saved in tmp_trainer\\checkpoint-49000\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2218, 'learning_rate': 3.829338157696367e-06, 'epoch': 2.77}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in tmp_trainer\\checkpoint-49000\\pytorch_model.bin\n",
      " 93%|█████████▎| 49500/53064 [2:43:48<11:16,  5.26it/s]Saving model checkpoint to tmp_trainer\\checkpoint-49500\n",
      "Configuration saved in tmp_trainer\\checkpoint-49500\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2356, 'learning_rate': 3.358208955223881e-06, 'epoch': 2.8}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in tmp_trainer\\checkpoint-49500\\pytorch_model.bin\n",
      " 94%|█████████▍| 50000/53064 [2:45:25<09:32,  5.35it/s]Saving model checkpoint to tmp_trainer\\checkpoint-50000\n",
      "Configuration saved in tmp_trainer\\checkpoint-50000\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2186, 'learning_rate': 2.8870797527513946e-06, 'epoch': 2.83}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in tmp_trainer\\checkpoint-50000\\pytorch_model.bin\n",
      " 95%|█████████▌| 50500/53064 [2:47:02<08:10,  5.23it/s]Saving model checkpoint to tmp_trainer\\checkpoint-50500\n",
      "Configuration saved in tmp_trainer\\checkpoint-50500\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2258, 'learning_rate': 2.4159505502789087e-06, 'epoch': 2.86}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in tmp_trainer\\checkpoint-50500\\pytorch_model.bin\n",
      " 96%|█████████▌| 51000/53064 [2:48:38<06:31,  5.28it/s]Saving model checkpoint to tmp_trainer\\checkpoint-51000\n",
      "Configuration saved in tmp_trainer\\checkpoint-51000\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.215, 'learning_rate': 1.944821347806423e-06, 'epoch': 2.88}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in tmp_trainer\\checkpoint-51000\\pytorch_model.bin\n",
      " 97%|█████████▋| 51500/53064 [2:50:14<04:54,  5.30it/s]Saving model checkpoint to tmp_trainer\\checkpoint-51500\n",
      "Configuration saved in tmp_trainer\\checkpoint-51500\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2307, 'learning_rate': 1.4736921453339366e-06, 'epoch': 2.91}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in tmp_trainer\\checkpoint-51500\\pytorch_model.bin\n",
      " 98%|█████████▊| 52000/53064 [2:51:51<03:24,  5.21it/s]Saving model checkpoint to tmp_trainer\\checkpoint-52000\n",
      "Configuration saved in tmp_trainer\\checkpoint-52000\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2136, 'learning_rate': 1.0025629428614503e-06, 'epoch': 2.94}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in tmp_trainer\\checkpoint-52000\\pytorch_model.bin\n",
      " 99%|█████████▉| 52500/53064 [2:53:28<01:47,  5.25it/s]Saving model checkpoint to tmp_trainer\\checkpoint-52500\n",
      "Configuration saved in tmp_trainer\\checkpoint-52500\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2611, 'learning_rate': 5.314337403889643e-07, 'epoch': 2.97}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in tmp_trainer\\checkpoint-52500\\pytorch_model.bin\n",
      "100%|█████████▉| 53000/53064 [2:55:04<00:12,  5.27it/s]Saving model checkpoint to tmp_trainer\\checkpoint-53000\n",
      "Configuration saved in tmp_trainer\\checkpoint-53000\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.223, 'learning_rate': 6.030453791647821e-08, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in tmp_trainer\\checkpoint-53000\\pytorch_model.bin\n",
      "100%|██████████| 53064/53064 [2:55:18<00:00,  5.29it/s]\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "100%|██████████| 53064/53064 [2:55:18<00:00,  5.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 10518.9268, 'train_samples_per_second': 40.356, 'train_steps_per_second': 5.045, 'train_loss': 0.3146891367124537, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=53064, training_loss=0.3146891367124537, metrics={'train_runtime': 10518.9268, 'train_samples_per_second': 40.356, 'train_steps_per_second': 5.045, 'train_loss': 0.3146891367124537, 'epoch': 3.0})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train\n",
    "trainer = Trainer(model=model, train_dataset=encoded_train, eval_dataset=encoded_validation)\n",
    "\n",
    "trainer.train()    \n",
    "#trainer.train(resume_from_checkpoint=True) # True if already trained, to save time by continuing on a checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in simcse_qqp\\config.json\n",
      "Model weights saved in simcse_qqp\\pytorch_model.bin\n"
     ]
    }
   ],
   "source": [
    "# save the fine_tuned model\n",
    "model.save_pretrained(\"simcse_qqp\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess the evaluation dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default\n",
      "Reusing dataset quora (C:\\Users\\52673\\.cache\\huggingface\\datasets\\quora\\default\\0.0.0\\36ba4cd42107f051a158016f1bea6ae3f4685c5df843529108a54e42d86c1e04)\n",
      "Using custom data configuration default\n",
      "Reusing dataset quora (C:\\Users\\52673\\.cache\\huggingface\\datasets\\quora\\default\\0.0.0\\36ba4cd42107f051a158016f1bea6ae3f4685c5df843529108a54e42d86c1e04)\n",
      "Loading cached processed dataset at C:\\Users\\52673\\.cache\\huggingface\\datasets\\quora\\default\\0.0.0\\36ba4cd42107f051a158016f1bea6ae3f4685c5df843529108a54e42d86c1e04\\cache-58ce8a2d3d13bc51.arrow\n",
      "Loading cached processed dataset at C:\\Users\\52673\\.cache\\huggingface\\datasets\\quora\\default\\0.0.0\\36ba4cd42107f051a158016f1bea6ae3f4685c5df843529108a54e42d86c1e04\\cache-077de9dbe62a5b12.arrow\n",
      "loading configuration file https://huggingface.co/princeton-nlp/sup-simcse-bert-base-uncased/resolve/main/config.json from cache at C:\\Users\\52673/.cache\\huggingface\\transformers\\886dba277a27c6ab50ab3d0bfd8839d354cfeed717289623026415c62b687338.1b14bcddba43d86a607eedb4b638b87d30aa00c839358953dbd36f2cd3317c83\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"result/bert-base-uncased-cls_before_pooler-sym_mlp-mlp_bert-bs64-gpu8-gs1-lr5e-5-m=stsb-norm0.05-l32-contra\",\n",
      "  \"architectures\": [\n",
      "    \"BertModel\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.9.2\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading file https://huggingface.co/princeton-nlp/sup-simcse-bert-base-uncased/resolve/main/vocab.txt from cache at C:\\Users\\52673/.cache\\huggingface\\transformers\\09102786ff74bdc2d32e48fb8505b1d86fd33b33c1e1f149322505c3fcc8926e.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99\n",
      "loading file https://huggingface.co/princeton-nlp/sup-simcse-bert-base-uncased/resolve/main/tokenizer.json from cache at None\n",
      "loading file https://huggingface.co/princeton-nlp/sup-simcse-bert-base-uncased/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/princeton-nlp/sup-simcse-bert-base-uncased/resolve/main/special_tokens_map.json from cache at C:\\Users\\52673/.cache\\huggingface\\transformers\\8c406286308d13c3a53bc10c3d1a2d5113d4e46a34cb6ec5ee06e5d9762c462c.dd8bd9bfd3664b530ea4e645105f557769387b3da9f79bdb55ed556bdd80611d\n",
      "loading file https://huggingface.co/princeton-nlp/sup-simcse-bert-base-uncased/resolve/main/tokenizer_config.json from cache at C:\\Users\\52673/.cache\\huggingface\\transformers\\4f2880ff62576ab971eea56ed4efbe8766ec79f9b35011e7ee8260a7feb608b8.8b6dccc90d16201c6d7ab0f3c6cc38e74b5f2fe587f6efadc9fa71fc0a00c606\n",
      "loading configuration file https://huggingface.co/princeton-nlp/sup-simcse-bert-base-uncased/resolve/main/config.json from cache at C:\\Users\\52673/.cache\\huggingface\\transformers\\886dba277a27c6ab50ab3d0bfd8839d354cfeed717289623026415c62b687338.1b14bcddba43d86a607eedb4b638b87d30aa00c839358953dbd36f2cd3317c83\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"result/bert-base-uncased-cls_before_pooler-sym_mlp-mlp_bert-bs64-gpu8-gs1-lr5e-5-m=stsb-norm0.05-l32-contra\",\n",
      "  \"architectures\": [\n",
      "    \"BertModel\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.9.2\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading configuration file https://huggingface.co/princeton-nlp/sup-simcse-bert-base-uncased/resolve/main/config.json from cache at C:\\Users\\52673/.cache\\huggingface\\transformers\\886dba277a27c6ab50ab3d0bfd8839d354cfeed717289623026415c62b687338.1b14bcddba43d86a607eedb4b638b87d30aa00c839358953dbd36f2cd3317c83\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"result/bert-base-uncased-cls_before_pooler-sym_mlp-mlp_bert-bs64-gpu8-gs1-lr5e-5-m=stsb-norm0.05-l32-contra\",\n",
      "  \"architectures\": [\n",
      "    \"BertModel\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.9.2\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "100%|██████████| 141501/141501 [00:33<00:00, 4216.25ex/s]\n",
      "100%|██████████| 60644/60644 [00:13<00:00, 4488.30ex/s]\n"
     ]
    }
   ],
   "source": [
    "# sampling the evaluation dataset from QQP\n",
    "train_eval = load_dataset(\"quora\", split = 'train[50%:85%]')\n",
    "validation_eval = load_dataset(\"quora\", split = 'train[85%:100%]')\n",
    "\n",
    "# repeat all the preprocessing steps above\n",
    "new_features = train_eval.features.copy()\n",
    "new_features[\"is_duplicate\"] = Value('int32')\n",
    "train_eval = train_eval.cast(new_features)\n",
    "\n",
    "new_features = validation_eval.features.copy()\n",
    "new_features[\"is_duplicate\"] = Value('int32')\n",
    "validation_eval = validation_eval.cast(new_features)\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained('princeton-nlp/sup-simcse-bert-base-uncased')\n",
    "\n",
    "\n",
    "# encode the training dataset in the form of sentences pair\n",
    "encoded_train_eval = train_eval.map(lambda batch: tokenizer(batch['questions']['text'][0], batch['questions']['text'][1], \n",
    "                                                  padding='max_length', truncation=True, max_length=64))\n",
    "encoded_train_eval.rename_column_(\"is_duplicate\", \"labels\")\n",
    "\n",
    "# encode the validation dataset in the form of sentences pair\n",
    "encoded_validation_eval = validation_eval.map(lambda batch: tokenizer(batch['questions']['text'][0], batch['questions']['text'][1], \n",
    "                                                            padding='max_length', truncation=True, max_length=64))\n",
    "encoded_validation_eval.rename_column_(\"is_duplicate\", \"labels\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load fine-tuned model and evaluation metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file simcse_qqp\\config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"princeton-nlp/sup-simcse-bert-base-uncased\",\n",
      "  \"architectures\": [\n",
      "    \"BertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"problem_type\": \"single_label_classification\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.9.2\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading weights file simcse_qqp\\pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing BertForSequenceClassification.\n",
      "\n",
      "All the weights of BertForSequenceClassification were initialized from the model checkpoint at simcse_qqp.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForSequenceClassification for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "# load the fine-tuned CL-BERT model\n",
    "simcse_qqp = AutoModelForSequenceClassification.from_pretrained(\"simcse_qqp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the metric module to compute accuracy and f1 score\n",
    "accuracy = load_metric(\"accuracy\")\n",
    "f1 = load_metric(\"f1\")\n",
    "\n",
    "def compute_accuracy(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    return accuracy.compute(predictions=predictions, references=labels)\n",
    "\n",
    "def compute_f1(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    return f1.compute(predictions=predictions, references=labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No `TrainingArguments` passed, using `output_dir=tmp_trainer`.\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: questions.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 60644\n",
      "  Batch size = 8\n",
      "100%|██████████| 7581/7581 [04:21<00:00, 28.94it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.470206081867218,\n",
       " 'eval_accuracy': 0.8765252951652266,\n",
       " 'eval_runtime': 261.9957,\n",
       " 'eval_samples_per_second': 231.469,\n",
       " 'eval_steps_per_second': 28.936}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer_qqp = Trainer(\n",
    "    model=simcse_qqp,    #use the fine-tuned model saved on\n",
    "    train_dataset=encoded_train_eval,\n",
    "    eval_dataset=encoded_validation_eval,\n",
    "    compute_metrics=compute_accuracy,\n",
    ")\n",
    "\n",
    "trainer_qqp.evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## F1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No `TrainingArguments` passed, using `output_dir=tmp_trainer`.\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: questions.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 60644\n",
      "  Batch size = 8\n",
      "100%|██████████| 7581/7581 [04:19<00:00, 29.24it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.470206081867218,\n",
       " 'eval_f1': 0.8327824921840107,\n",
       " 'eval_runtime': 259.3576,\n",
       " 'eval_samples_per_second': 233.824,\n",
       " 'eval_steps_per_second': 29.23}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer_qqp = Trainer(\n",
    "    model=simcse_qqp,    #use the fine-tuned model saved on\n",
    "    train_dataset=encoded_train_eval,\n",
    "    eval_dataset=encoded_validation_eval,\n",
    "    compute_metrics=compute_f1,\n",
    ")\n",
    "\n",
    "trainer_qqp.evaluate() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "01cce90487304195a98c1fadead284adb0ca16778f239acdcba59c3951b79f2e"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

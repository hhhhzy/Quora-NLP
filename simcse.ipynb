{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from scipy.spatial.distance import cosine\n",
    "from transformers import AutoModel, AutoTokenizer, Trainer, AutoModelForSequenceClassification, BertForSequenceClassification, BertConfig,BertModel\n",
    "from datasets import load_dataset, ClassLabel, Value, load_metric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.Prepare dataset for finetuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/princeton-nlp/sup-simcse-bert-base-uncased/resolve/main/config.json from cache at C:\\Users\\52673/.cache\\huggingface\\transformers\\886dba277a27c6ab50ab3d0bfd8839d354cfeed717289623026415c62b687338.1b14bcddba43d86a607eedb4b638b87d30aa00c839358953dbd36f2cd3317c83\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"result/bert-base-uncased-cls_before_pooler-sym_mlp-mlp_bert-bs64-gpu8-gs1-lr5e-5-m=stsb-norm0.05-l32-contra\",\n",
      "  \"architectures\": [\n",
      "    \"BertModel\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.9.2\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading file https://huggingface.co/princeton-nlp/sup-simcse-bert-base-uncased/resolve/main/vocab.txt from cache at C:\\Users\\52673/.cache\\huggingface\\transformers\\09102786ff74bdc2d32e48fb8505b1d86fd33b33c1e1f149322505c3fcc8926e.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99\n",
      "loading file https://huggingface.co/princeton-nlp/sup-simcse-bert-base-uncased/resolve/main/tokenizer.json from cache at None\n",
      "loading file https://huggingface.co/princeton-nlp/sup-simcse-bert-base-uncased/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/princeton-nlp/sup-simcse-bert-base-uncased/resolve/main/special_tokens_map.json from cache at C:\\Users\\52673/.cache\\huggingface\\transformers\\8c406286308d13c3a53bc10c3d1a2d5113d4e46a34cb6ec5ee06e5d9762c462c.dd8bd9bfd3664b530ea4e645105f557769387b3da9f79bdb55ed556bdd80611d\n",
      "loading file https://huggingface.co/princeton-nlp/sup-simcse-bert-base-uncased/resolve/main/tokenizer_config.json from cache at C:\\Users\\52673/.cache\\huggingface\\transformers\\4f2880ff62576ab971eea56ed4efbe8766ec79f9b35011e7ee8260a7feb608b8.8b6dccc90d16201c6d7ab0f3c6cc38e74b5f2fe587f6efadc9fa71fc0a00c606\n",
      "loading configuration file https://huggingface.co/princeton-nlp/sup-simcse-bert-base-uncased/resolve/main/config.json from cache at C:\\Users\\52673/.cache\\huggingface\\transformers\\886dba277a27c6ab50ab3d0bfd8839d354cfeed717289623026415c62b687338.1b14bcddba43d86a607eedb4b638b87d30aa00c839358953dbd36f2cd3317c83\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"result/bert-base-uncased-cls_before_pooler-sym_mlp-mlp_bert-bs64-gpu8-gs1-lr5e-5-m=stsb-norm0.05-l32-contra\",\n",
      "  \"architectures\": [\n",
      "    \"BertModel\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.9.2\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading configuration file https://huggingface.co/princeton-nlp/sup-simcse-bert-base-uncased/resolve/main/config.json from cache at C:\\Users\\52673/.cache\\huggingface\\transformers\\886dba277a27c6ab50ab3d0bfd8839d354cfeed717289623026415c62b687338.1b14bcddba43d86a607eedb4b638b87d30aa00c839358953dbd36f2cd3317c83\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"result/bert-base-uncased-cls_before_pooler-sym_mlp-mlp_bert-bs64-gpu8-gs1-lr5e-5-m=stsb-norm0.05-l32-contra\",\n",
      "  \"architectures\": [\n",
      "    \"BertModel\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.9.2\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# load the tokenizer pretrained on bert-base\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"princeton-nlp/sup-simcse-bert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default\n",
      "Reusing dataset quora (C:\\Users\\52673\\.cache\\huggingface\\datasets\\quora\\default\\0.0.0\\36ba4cd42107f051a158016f1bea6ae3f4685c5df843529108a54e42d86c1e04)\n",
      "Using custom data configuration default\n",
      "Reusing dataset quora (C:\\Users\\52673\\.cache\\huggingface\\datasets\\quora\\default\\0.0.0\\36ba4cd42107f051a158016f1bea6ae3f4685c5df843529108a54e42d86c1e04)\n"
     ]
    }
   ],
   "source": [
    "# sampling the dataset for fine-tuning\n",
    "train = load_dataset(\"quora\", split = 'train[:35%]')     # classic 7/3 split\n",
    "validation = load_dataset(\"quora\", split = 'train[35%:50%]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at C:\\Users\\52673\\.cache\\huggingface\\datasets\\quora\\default\\0.0.0\\36ba4cd42107f051a158016f1bea6ae3f4685c5df843529108a54e42d86c1e04\\cache-0474a84a76505170.arrow\n",
      "Loading cached processed dataset at C:\\Users\\52673\\.cache\\huggingface\\datasets\\quora\\default\\0.0.0\\36ba4cd42107f051a158016f1bea6ae3f4685c5df843529108a54e42d86c1e04\\cache-387810a1332fde55.arrow\n"
     ]
    }
   ],
   "source": [
    "# convert the dtype of 'is_duplicate' to int\n",
    "new_features = train.features.copy()\n",
    "new_features[\"is_duplicate\"] = Value('int32')\n",
    "train = train.cast(new_features)\n",
    "\n",
    "new_features = validation.features.copy()\n",
    "new_features[\"is_duplicate\"] = Value('int32')\n",
    "validation = validation.cast(new_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at C:\\Users\\52673\\.cache\\huggingface\\datasets\\quora\\default\\0.0.0\\36ba4cd42107f051a158016f1bea6ae3f4685c5df843529108a54e42d86c1e04\\cache-94540c3e4c186fdb.arrow\n"
     ]
    }
   ],
   "source": [
    "# encode the training dataset in the form of sentences pair\n",
    "# truncate at length=64 for a balance of time consuming and information coverage\n",
    "encoded_train = train.map(lambda batch: tokenizer(batch['questions']['text'][0], batch['questions']['text'][1], \n",
    "                                                  padding='max_length', truncation=True, max_length=64))\n",
    "encoded_train.rename_column_(\"is_duplicate\", \"labels\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 60643/60643 [00:31<00:00, 1950.24ex/s]\n"
     ]
    }
   ],
   "source": [
    "# encode the validation dataset in the form of sentences pair\n",
    "encoded_validation = validation.map(lambda batch: tokenizer(batch['questions']['text'][0], batch['questions']['text'][1], \n",
    "                                                            padding='max_length', truncation=True, max_length=64))\n",
    "encoded_validation.rename_column_(\"is_duplicate\", \"labels\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_train.set_format(\"torch\", columns=[\"input_ids\", \"token_type_ids\", \"attention_mask\", \"labels\"])\n",
    "encoded_validation.set_format(\"torch\", columns=[\"input_ids\", \"token_type_ids\", \"attention_mask\", \"labels\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'labels': torch.Size([]), 'input_ids': torch.Size([64]), 'token_type_ids': torch.Size([64]), 'attention_mask': torch.Size([64])}\n",
      "{'labels': torch.Size([]), 'input_ids': torch.Size([64]), 'token_type_ids': torch.Size([64]), 'attention_mask': torch.Size([64])}\n"
     ]
    }
   ],
   "source": [
    "# check if the format is valid, and if each tensor have the same size\n",
    "print({key: val.shape for key, val in encoded_validation[0].items()})\n",
    "print({key: val.shape for key, val in encoded_validation[1].items()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'labels': tensor(0),\n",
       " 'input_ids': tensor([  101,  2054,  2003,  1996,  2466,  1997, 12849, 10606, 16506,  1006,\n",
       "         12849,  2232,  1011,  1045,  1011,  2053,  2953,  1007,  6323,  1029,\n",
       "           102,  2054,  2052,  4148,  2065,  1996,  2796,  2231, 10312,  1996,\n",
       "         12849, 10606, 16506,  1006, 12849,  2232,  1011,  1045,  1011,  2053,\n",
       "          2953,  1007,  6323,  2067,  1029,   102,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0]),\n",
       " 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# take a look at an encoded sample\n",
    "encoded_train[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Fine-tune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# another way to load pretrained weights\n",
    "output_config_file = \"./config.json\"\n",
    "output_model_file = \"./sup-simcse.bin\"\n",
    "\n",
    "config = BertConfig.from_json_file(output_config_file)\n",
    "model = BertModel(config = config)\n",
    "state_dict = torch.load(output_model_file)\n",
    "model.load_state_dict(state_dict)\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/princeton-nlp/sup-simcse-bert-base-uncased/resolve/main/config.json from cache at C:\\Users\\52673/.cache\\huggingface\\transformers\\886dba277a27c6ab50ab3d0bfd8839d354cfeed717289623026415c62b687338.1b14bcddba43d86a607eedb4b638b87d30aa00c839358953dbd36f2cd3317c83\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"result/bert-base-uncased-cls_before_pooler-sym_mlp-mlp_bert-bs64-gpu8-gs1-lr5e-5-m=stsb-norm0.05-l32-contra\",\n",
      "  \"architectures\": [\n",
      "    \"BertModel\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.9.2\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/princeton-nlp/sup-simcse-bert-base-uncased/resolve/main/pytorch_model.bin from cache at C:\\Users\\52673/.cache\\huggingface\\transformers\\4c860a500382bddac6cccf88a682fd0a1bda5b282522cb42f1144306aa172416.ccdfe081eeadaaa135da8becf0290d82d3956ea27e3929311aa3985f3a5a320d\n",
      "All model checkpoint weights were used when initializing BertForSequenceClassification.\n",
      "\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at princeton-nlp/sup-simcse-bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# load pretrained weights to initialize Bert\n",
    "model = BertForSequenceClassification.from_pretrained(\"princeton-nlp/sup-simcse-bert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean up gpu cache before training\n",
    "import gc\n",
    "\n",
    "gc.collect()\n",
    "\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the training set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: questions.\n",
      "***** Running training *****\n",
      "  Num examples = 141502\n",
      "  Num Epochs = 3\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 53064\n",
      "  1%|          | 500/53064 [01:42<2:57:48,  4.93it/s]Saving model checkpoint to tmp_trainer\\checkpoint-500\n",
      "Configuration saved in tmp_trainer\\checkpoint-500\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6375, 'learning_rate': 4.9528870797527514e-05, 'epoch': 0.03}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in tmp_trainer\\checkpoint-500\\pytorch_model.bin\n",
      "  2%|▏         | 1000/53064 [03:26<2:54:51,  4.96it/s]Saving model checkpoint to tmp_trainer\\checkpoint-1000\n",
      "Configuration saved in tmp_trainer\\checkpoint-1000\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6511, 'learning_rate': 4.9057741595055026e-05, 'epoch': 0.06}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in tmp_trainer\\checkpoint-1000\\pytorch_model.bin\n",
      "  3%|▎         | 1500/53064 [05:06<2:43:17,  5.26it/s]Saving model checkpoint to tmp_trainer\\checkpoint-1500\n",
      "Configuration saved in tmp_trainer\\checkpoint-1500\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.661, 'learning_rate': 4.8586612392582545e-05, 'epoch': 0.08}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in tmp_trainer\\checkpoint-1500\\pytorch_model.bin\n",
      "  4%|▍         | 2000/53064 [06:46<2:44:57,  5.16it/s]Saving model checkpoint to tmp_trainer\\checkpoint-2000\n",
      "Configuration saved in tmp_trainer\\checkpoint-2000\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.654, 'learning_rate': 4.811548319011006e-05, 'epoch': 0.11}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in tmp_trainer\\checkpoint-2000\\pytorch_model.bin\n",
      "  5%|▍         | 2500/53064 [08:28<2:51:12,  4.92it/s]Saving model checkpoint to tmp_trainer\\checkpoint-2500\n",
      "Configuration saved in tmp_trainer\\checkpoint-2500\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6699, 'learning_rate': 4.7644353987637576e-05, 'epoch': 0.14}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in tmp_trainer\\checkpoint-2500\\pytorch_model.bin\n",
      "  6%|▌         | 3000/53064 [10:11<2:42:39,  5.13it/s]Saving model checkpoint to tmp_trainer\\checkpoint-3000\n",
      "Configuration saved in tmp_trainer\\checkpoint-3000\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6653, 'learning_rate': 4.717322478516509e-05, 'epoch': 0.17}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in tmp_trainer\\checkpoint-3000\\pytorch_model.bin\n",
      "  7%|▋         | 3500/53064 [11:53<2:41:16,  5.12it/s]Saving model checkpoint to tmp_trainer\\checkpoint-3500\n",
      "Configuration saved in tmp_trainer\\checkpoint-3500\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6694, 'learning_rate': 4.67020955826926e-05, 'epoch': 0.2}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in tmp_trainer\\checkpoint-3500\\pytorch_model.bin\n",
      "  8%|▊         | 4000/53064 [13:33<2:37:18,  5.20it/s]Saving model checkpoint to tmp_trainer\\checkpoint-4000\n",
      "Configuration saved in tmp_trainer\\checkpoint-4000\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6673, 'learning_rate': 4.623096638022011e-05, 'epoch': 0.23}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in tmp_trainer\\checkpoint-4000\\pytorch_model.bin\n",
      "  8%|▊         | 4500/53064 [15:16<2:41:45,  5.00it/s]Saving model checkpoint to tmp_trainer\\checkpoint-4500\n",
      "Configuration saved in tmp_trainer\\checkpoint-4500\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6658, 'learning_rate': 4.575983717774763e-05, 'epoch': 0.25}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in tmp_trainer\\checkpoint-4500\\pytorch_model.bin\n",
      "  9%|▉         | 5000/53064 [16:56<2:32:35,  5.25it/s]Saving model checkpoint to tmp_trainer\\checkpoint-5000\n",
      "Configuration saved in tmp_trainer\\checkpoint-5000\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6683, 'learning_rate': 4.528870797527514e-05, 'epoch': 0.28}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in tmp_trainer\\checkpoint-5000\\pytorch_model.bin\n",
      " 10%|█         | 5500/53064 [19:01<3:49:12,  3.46it/s]Saving model checkpoint to tmp_trainer\\checkpoint-5500\n",
      "Configuration saved in tmp_trainer\\checkpoint-5500\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6669, 'learning_rate': 4.4817578772802655e-05, 'epoch': 0.31}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in tmp_trainer\\checkpoint-5500\\pytorch_model.bin\n",
      " 11%|█▏        | 6000/53064 [21:46<4:51:09,  2.69it/s]Saving model checkpoint to tmp_trainer\\checkpoint-6000\n",
      "Configuration saved in tmp_trainer\\checkpoint-6000\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.669, 'learning_rate': 4.434644957033017e-05, 'epoch': 0.34}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in tmp_trainer\\checkpoint-6000\\pytorch_model.bin\n",
      " 12%|█▏        | 6500/53064 [25:01<4:43:48,  2.73it/s]Saving model checkpoint to tmp_trainer\\checkpoint-6500\n",
      "Configuration saved in tmp_trainer\\checkpoint-6500\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6687, 'learning_rate': 4.387532036785768e-05, 'epoch': 0.37}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in tmp_trainer\\checkpoint-6500\\pytorch_model.bin\n",
      " 13%|█▎        | 7000/53064 [28:19<5:06:26,  2.51it/s]Saving model checkpoint to tmp_trainer\\checkpoint-7000\n",
      "Configuration saved in tmp_trainer\\checkpoint-7000\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6638, 'learning_rate': 4.34041911653852e-05, 'epoch': 0.4}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in tmp_trainer\\checkpoint-7000\\pytorch_model.bin\n",
      " 14%|█▍        | 7500/53064 [31:35<4:48:19,  2.63it/s]Saving model checkpoint to tmp_trainer\\checkpoint-7500\n",
      "Configuration saved in tmp_trainer\\checkpoint-7500\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6694, 'learning_rate': 4.293306196291271e-05, 'epoch': 0.42}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in tmp_trainer\\checkpoint-7500\\pytorch_model.bin\n",
      " 15%|█▌        | 8000/53064 [34:52<4:53:49,  2.56it/s]Saving model checkpoint to tmp_trainer\\checkpoint-8000\n",
      "Configuration saved in tmp_trainer\\checkpoint-8000\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6709, 'learning_rate': 4.246193276044023e-05, 'epoch': 0.45}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in tmp_trainer\\checkpoint-8000\\pytorch_model.bin\n",
      " 16%|█▌        | 8500/53064 [37:08<2:24:55,  5.13it/s]Saving model checkpoint to tmp_trainer\\checkpoint-8500\n",
      "Configuration saved in tmp_trainer\\checkpoint-8500\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6737, 'learning_rate': 4.199080355796774e-05, 'epoch': 0.48}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in tmp_trainer\\checkpoint-8500\\pytorch_model.bin\n",
      " 17%|█▋        | 9000/53064 [38:55<2:39:12,  4.61it/s]Saving model checkpoint to tmp_trainer\\checkpoint-9000\n",
      "Configuration saved in tmp_trainer\\checkpoint-9000\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6643, 'learning_rate': 4.151967435549525e-05, 'epoch': 0.51}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in tmp_trainer\\checkpoint-9000\\pytorch_model.bin\n",
      " 18%|█▊        | 9500/53064 [41:20<2:47:49,  4.33it/s]Saving model checkpoint to tmp_trainer\\checkpoint-9500\n",
      "Configuration saved in tmp_trainer\\checkpoint-9500\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6699, 'learning_rate': 4.1048545153022765e-05, 'epoch': 0.54}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in tmp_trainer\\checkpoint-9500\\pytorch_model.bin\n",
      " 19%|█▉        | 10000/53064 [44:23<4:53:41,  2.44it/s]Saving model checkpoint to tmp_trainer\\checkpoint-10000\n",
      "Configuration saved in tmp_trainer\\checkpoint-10000\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6588, 'learning_rate': 4.057741595055028e-05, 'epoch': 0.57}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in tmp_trainer\\checkpoint-10000\\pytorch_model.bin\n",
      " 20%|█▉        | 10500/53064 [47:43<4:17:00,  2.76it/s]Saving model checkpoint to tmp_trainer\\checkpoint-10500\n",
      "Configuration saved in tmp_trainer\\checkpoint-10500\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6651, 'learning_rate': 4.0106286748077796e-05, 'epoch': 0.59}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in tmp_trainer\\checkpoint-10500\\pytorch_model.bin\n",
      " 21%|██        | 11000/53064 [51:02<4:24:43,  2.65it/s]Saving model checkpoint to tmp_trainer\\checkpoint-11000\n",
      "Configuration saved in tmp_trainer\\checkpoint-11000\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6675, 'learning_rate': 3.9635157545605314e-05, 'epoch': 0.62}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in tmp_trainer\\checkpoint-11000\\pytorch_model.bin\n",
      " 22%|██▏       | 11500/53064 [54:25<4:26:46,  2.60it/s]Saving model checkpoint to tmp_trainer\\checkpoint-11500\n",
      "Configuration saved in tmp_trainer\\checkpoint-11500\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6679, 'learning_rate': 3.9164028343132826e-05, 'epoch': 0.65}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in tmp_trainer\\checkpoint-11500\\pytorch_model.bin\n",
      " 23%|██▎       | 12000/53064 [57:43<4:26:14,  2.57it/s]Saving model checkpoint to tmp_trainer\\checkpoint-12000\n",
      "Configuration saved in tmp_trainer\\checkpoint-12000\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6672, 'learning_rate': 3.869289914066034e-05, 'epoch': 0.68}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in tmp_trainer\\checkpoint-12000\\pytorch_model.bin\n",
      " 24%|██▎       | 12500/53064 [1:01:03<4:23:45,  2.56it/s]Saving model checkpoint to tmp_trainer\\checkpoint-12500\n",
      "Configuration saved in tmp_trainer\\checkpoint-12500\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6579, 'learning_rate': 3.822176993818785e-05, 'epoch': 0.71}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in tmp_trainer\\checkpoint-12500\\pytorch_model.bin\n",
      " 24%|██▍       | 13000/53064 [1:04:17<4:08:06,  2.69it/s]Saving model checkpoint to tmp_trainer\\checkpoint-13000\n",
      "Configuration saved in tmp_trainer\\checkpoint-13000\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.66, 'learning_rate': 3.775064073571536e-05, 'epoch': 0.73}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in tmp_trainer\\checkpoint-13000\\pytorch_model.bin\n",
      " 25%|██▌       | 13500/53064 [1:07:33<4:15:01,  2.59it/s]Saving model checkpoint to tmp_trainer\\checkpoint-13500\n",
      "Configuration saved in tmp_trainer\\checkpoint-13500\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6622, 'learning_rate': 3.727951153324288e-05, 'epoch': 0.76}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in tmp_trainer\\checkpoint-13500\\pytorch_model.bin\n",
      " 26%|██▋       | 14000/53064 [1:10:05<2:20:47,  4.62it/s]Saving model checkpoint to tmp_trainer\\checkpoint-14000\n",
      "Configuration saved in tmp_trainer\\checkpoint-14000\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6544, 'learning_rate': 3.680838233077039e-05, 'epoch': 0.79}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in tmp_trainer\\checkpoint-14000\\pytorch_model.bin\n",
      " 27%|██▋       | 14500/53064 [1:11:59<5:07:08,  2.09it/s]Saving model checkpoint to tmp_trainer\\checkpoint-14500\n",
      "Configuration saved in tmp_trainer\\checkpoint-14500\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6617, 'learning_rate': 3.6337253128297905e-05, 'epoch': 0.82}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in tmp_trainer\\checkpoint-14500\\pytorch_model.bin\n",
      " 28%|██▊       | 15000/53064 [1:15:21<3:55:50,  2.69it/s]Saving model checkpoint to tmp_trainer\\checkpoint-15000\n",
      "Configuration saved in tmp_trainer\\checkpoint-15000\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6602, 'learning_rate': 3.586612392582542e-05, 'epoch': 0.85}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in tmp_trainer\\checkpoint-15000\\pytorch_model.bin\n",
      " 29%|██▉       | 15500/53064 [1:18:36<3:49:28,  2.73it/s]Saving model checkpoint to tmp_trainer\\checkpoint-15500\n",
      "Configuration saved in tmp_trainer\\checkpoint-15500\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.662, 'learning_rate': 3.5394994723352936e-05, 'epoch': 0.88}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in tmp_trainer\\checkpoint-15500\\pytorch_model.bin\n",
      " 30%|███       | 16000/53064 [1:21:55<3:53:36,  2.64it/s]Saving model checkpoint to tmp_trainer\\checkpoint-16000\n",
      "Configuration saved in tmp_trainer\\checkpoint-16000\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6596, 'learning_rate': 3.492386552088045e-05, 'epoch': 0.9}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in tmp_trainer\\checkpoint-16000\\pytorch_model.bin\n",
      " 31%|███       | 16500/53064 [1:25:11<3:57:26,  2.57it/s]Saving model checkpoint to tmp_trainer\\checkpoint-16500\n",
      "Configuration saved in tmp_trainer\\checkpoint-16500\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.666, 'learning_rate': 3.445273631840796e-05, 'epoch': 0.93}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in tmp_trainer\\checkpoint-16500\\pytorch_model.bin\n",
      " 32%|███▏      | 17000/53064 [1:28:27<2:48:33,  3.57it/s]Saving model checkpoint to tmp_trainer\\checkpoint-17000\n",
      "Configuration saved in tmp_trainer\\checkpoint-17000\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6657, 'learning_rate': 3.398160711593548e-05, 'epoch': 0.96}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in tmp_trainer\\checkpoint-17000\\pytorch_model.bin\n",
      " 33%|███▎      | 17500/53064 [1:30:43<2:04:37,  4.76it/s]Saving model checkpoint to tmp_trainer\\checkpoint-17500\n",
      "Configuration saved in tmp_trainer\\checkpoint-17500\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6571, 'learning_rate': 3.351047791346299e-05, 'epoch': 0.99}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in tmp_trainer\\checkpoint-17500\\pytorch_model.bin\n",
      " 34%|███▍      | 18000/53064 [1:33:28<3:36:15,  2.70it/s]Saving model checkpoint to tmp_trainer\\checkpoint-18000\n",
      "Configuration saved in tmp_trainer\\checkpoint-18000\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6626, 'learning_rate': 3.30393487109905e-05, 'epoch': 1.02}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in tmp_trainer\\checkpoint-18000\\pytorch_model.bin\n",
      " 35%|███▍      | 18500/53064 [1:36:44<3:57:54,  2.42it/s]Saving model checkpoint to tmp_trainer\\checkpoint-18500\n",
      "Configuration saved in tmp_trainer\\checkpoint-18500\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6586, 'learning_rate': 3.2568219508518015e-05, 'epoch': 1.05}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in tmp_trainer\\checkpoint-18500\\pytorch_model.bin\n",
      " 36%|███▌      | 19000/53064 [1:39:57<3:36:15,  2.63it/s]Saving model checkpoint to tmp_trainer\\checkpoint-19000\n",
      "Configuration saved in tmp_trainer\\checkpoint-19000\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6582, 'learning_rate': 3.209709030604553e-05, 'epoch': 1.07}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in tmp_trainer\\checkpoint-19000\\pytorch_model.bin\n",
      " 37%|███▋      | 19500/53064 [1:43:08<3:39:20,  2.55it/s]Saving model checkpoint to tmp_trainer\\checkpoint-19500\n",
      "Configuration saved in tmp_trainer\\checkpoint-19500\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6604, 'learning_rate': 3.1625961103573046e-05, 'epoch': 1.1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in tmp_trainer\\checkpoint-19500\\pytorch_model.bin\n",
      " 38%|███▊      | 20000/53064 [1:45:33<2:57:13,  3.11it/s]Saving model checkpoint to tmp_trainer\\checkpoint-20000\n",
      "Configuration saved in tmp_trainer\\checkpoint-20000\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6602, 'learning_rate': 3.1154831901100565e-05, 'epoch': 1.13}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in tmp_trainer\\checkpoint-20000\\pytorch_model.bin\n",
      " 39%|███▊      | 20500/53064 [1:48:30<3:35:34,  2.52it/s]Saving model checkpoint to tmp_trainer\\checkpoint-20500\n",
      "Configuration saved in tmp_trainer\\checkpoint-20500\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6603, 'learning_rate': 3.068370269862808e-05, 'epoch': 1.16}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in tmp_trainer\\checkpoint-20500\\pytorch_model.bin\n",
      " 40%|███▉      | 21000/53064 [1:51:49<3:17:27,  2.71it/s]Saving model checkpoint to tmp_trainer\\checkpoint-21000\n",
      "Configuration saved in tmp_trainer\\checkpoint-21000\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.661, 'learning_rate': 3.021257349615559e-05, 'epoch': 1.19}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in tmp_trainer\\checkpoint-21000\\pytorch_model.bin\n",
      " 41%|████      | 21500/53064 [1:55:10<3:28:28,  2.52it/s]Saving model checkpoint to tmp_trainer\\checkpoint-21500\n",
      "Configuration saved in tmp_trainer\\checkpoint-21500\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6669, 'learning_rate': 2.97414442936831e-05, 'epoch': 1.22}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in tmp_trainer\\checkpoint-21500\\pytorch_model.bin\n",
      " 41%|████▏     | 22000/53064 [1:58:33<3:43:55,  2.31it/s]Saving model checkpoint to tmp_trainer\\checkpoint-22000\n",
      "Configuration saved in tmp_trainer\\checkpoint-22000\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6657, 'learning_rate': 2.9270315091210616e-05, 'epoch': 1.24}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in tmp_trainer\\checkpoint-22000\\pytorch_model.bin\n",
      " 42%|████▏     | 22500/53064 [2:01:56<3:11:43,  2.66it/s]Saving model checkpoint to tmp_trainer\\checkpoint-22500\n",
      "Configuration saved in tmp_trainer\\checkpoint-22500\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6652, 'learning_rate': 2.8799185888738128e-05, 'epoch': 1.27}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in tmp_trainer\\checkpoint-22500\\pytorch_model.bin\n",
      " 43%|████▎     | 23000/53064 [2:05:15<2:24:49,  3.46it/s]Saving model checkpoint to tmp_trainer\\checkpoint-23000\n",
      "Configuration saved in tmp_trainer\\checkpoint-23000\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6585, 'learning_rate': 2.832805668626564e-05, 'epoch': 1.3}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in tmp_trainer\\checkpoint-23000\\pytorch_model.bin\n",
      " 44%|████▍     | 23500/53064 [2:07:41<3:18:27,  2.48it/s]Saving model checkpoint to tmp_trainer\\checkpoint-23500\n",
      "Configuration saved in tmp_trainer\\checkpoint-23500\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6617, 'learning_rate': 2.7856927483793156e-05, 'epoch': 1.33}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in tmp_trainer\\checkpoint-23500\\pytorch_model.bin\n",
      " 45%|████▌     | 24000/53064 [2:10:36<2:35:54,  3.11it/s]Saving model checkpoint to tmp_trainer\\checkpoint-24000\n",
      "Configuration saved in tmp_trainer\\checkpoint-24000\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6519, 'learning_rate': 2.7385798281320668e-05, 'epoch': 1.36}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in tmp_trainer\\checkpoint-24000\\pytorch_model.bin\n",
      " 46%|████▌     | 24500/53064 [2:13:24<2:30:45,  3.16it/s]Saving model checkpoint to tmp_trainer\\checkpoint-24500\n",
      "Configuration saved in tmp_trainer\\checkpoint-24500\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6645, 'learning_rate': 2.6914669078848186e-05, 'epoch': 1.39}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in tmp_trainer\\checkpoint-24500\\pytorch_model.bin\n",
      " 47%|████▋     | 25000/53064 [2:16:12<2:37:05,  2.98it/s]Saving model checkpoint to tmp_trainer\\checkpoint-25000\n",
      "Configuration saved in tmp_trainer\\checkpoint-25000\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6666, 'learning_rate': 2.6443539876375702e-05, 'epoch': 1.41}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in tmp_trainer\\checkpoint-25000\\pytorch_model.bin\n",
      " 48%|████▊     | 25500/53064 [2:19:03<2:31:24,  3.03it/s]Saving model checkpoint to tmp_trainer\\checkpoint-25500\n",
      "Configuration saved in tmp_trainer\\checkpoint-25500\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6547, 'learning_rate': 2.5972410673903214e-05, 'epoch': 1.44}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in tmp_trainer\\checkpoint-25500\\pytorch_model.bin\n",
      " 49%|████▉     | 26000/53064 [2:21:53<2:35:20,  2.90it/s]Saving model checkpoint to tmp_trainer\\checkpoint-26000\n",
      "Configuration saved in tmp_trainer\\checkpoint-26000\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6687, 'learning_rate': 2.5501281471430726e-05, 'epoch': 1.47}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in tmp_trainer\\checkpoint-26000\\pytorch_model.bin\n",
      " 50%|████▉     | 26500/53064 [2:24:39<2:18:26,  3.20it/s]Saving model checkpoint to tmp_trainer\\checkpoint-26500\n",
      "Configuration saved in tmp_trainer\\checkpoint-26500\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6641, 'learning_rate': 2.503015226895824e-05, 'epoch': 1.5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in tmp_trainer\\checkpoint-26500\\pytorch_model.bin\n",
      " 51%|█████     | 27000/53064 [2:26:50<1:29:42,  4.84it/s]Saving model checkpoint to tmp_trainer\\checkpoint-27000\n",
      "Configuration saved in tmp_trainer\\checkpoint-27000\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6528, 'learning_rate': 2.4559023066485753e-05, 'epoch': 1.53}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in tmp_trainer\\checkpoint-27000\\pytorch_model.bin\n",
      " 52%|█████▏    | 27500/53064 [2:28:41<1:27:41,  4.86it/s]Saving model checkpoint to tmp_trainer\\checkpoint-27500\n",
      "Configuration saved in tmp_trainer\\checkpoint-27500\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.663, 'learning_rate': 2.408789386401327e-05, 'epoch': 1.55}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in tmp_trainer\\checkpoint-27500\\pytorch_model.bin\n",
      " 53%|█████▎    | 28000/53064 [2:30:32<1:59:30,  3.50it/s]Saving model checkpoint to tmp_trainer\\checkpoint-28000\n",
      "Configuration saved in tmp_trainer\\checkpoint-28000\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6621, 'learning_rate': 2.3616764661540784e-05, 'epoch': 1.58}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in tmp_trainer\\checkpoint-28000\\pytorch_model.bin\n",
      " 54%|█████▎    | 28500/53064 [2:32:34<1:21:23,  5.03it/s]Saving model checkpoint to tmp_trainer\\checkpoint-28500\n",
      "Configuration saved in tmp_trainer\\checkpoint-28500\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6584, 'learning_rate': 2.3145635459068296e-05, 'epoch': 1.61}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in tmp_trainer\\checkpoint-28500\\pytorch_model.bin\n",
      " 55%|█████▍    | 29000/53064 [2:34:29<1:22:44,  4.85it/s]Saving model checkpoint to tmp_trainer\\checkpoint-29000\n",
      "Configuration saved in tmp_trainer\\checkpoint-29000\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6591, 'learning_rate': 2.2674506256595808e-05, 'epoch': 1.64}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in tmp_trainer\\checkpoint-29000\\pytorch_model.bin\n",
      " 56%|█████▌    | 29500/53064 [2:36:18<1:22:21,  4.77it/s]Saving model checkpoint to tmp_trainer\\checkpoint-29500\n",
      "Configuration saved in tmp_trainer\\checkpoint-29500\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6525, 'learning_rate': 2.2203377054123324e-05, 'epoch': 1.67}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in tmp_trainer\\checkpoint-29500\\pytorch_model.bin\n",
      " 57%|█████▋    | 30000/53064 [2:38:12<1:45:45,  3.63it/s]Saving model checkpoint to tmp_trainer\\checkpoint-30000\n",
      "Configuration saved in tmp_trainer\\checkpoint-30000\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6508, 'learning_rate': 2.173224785165084e-05, 'epoch': 1.7}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in tmp_trainer\\checkpoint-30000\\pytorch_model.bin\n",
      " 57%|█████▋    | 30500/53064 [2:41:01<2:20:28,  2.68it/s]Saving model checkpoint to tmp_trainer\\checkpoint-30500\n",
      "Configuration saved in tmp_trainer\\checkpoint-30500\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6614, 'learning_rate': 2.126111864917835e-05, 'epoch': 1.72}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in tmp_trainer\\checkpoint-30500\\pytorch_model.bin\n",
      " 58%|█████▊    | 31000/53064 [2:44:12<2:18:11,  2.66it/s]Saving model checkpoint to tmp_trainer\\checkpoint-31000\n",
      "Configuration saved in tmp_trainer\\checkpoint-31000\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6573, 'learning_rate': 2.0789989446705866e-05, 'epoch': 1.75}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in tmp_trainer\\checkpoint-31000\\pytorch_model.bin\n",
      " 59%|█████▉    | 31500/53064 [2:47:26<2:20:38,  2.56it/s]Saving model checkpoint to tmp_trainer\\checkpoint-31500\n",
      "Configuration saved in tmp_trainer\\checkpoint-31500\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6624, 'learning_rate': 2.031886024423338e-05, 'epoch': 1.78}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in tmp_trainer\\checkpoint-31500\\pytorch_model.bin\n",
      " 60%|██████    | 32000/53064 [2:50:43<2:15:09,  2.60it/s]Saving model checkpoint to tmp_trainer\\checkpoint-32000\n",
      "Configuration saved in tmp_trainer\\checkpoint-32000\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6634, 'learning_rate': 1.9847731041760894e-05, 'epoch': 1.81}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in tmp_trainer\\checkpoint-32000\\pytorch_model.bin\n",
      " 61%|██████    | 32500/53064 [2:53:58<2:12:22,  2.59it/s]Saving model checkpoint to tmp_trainer\\checkpoint-32500\n",
      "Configuration saved in tmp_trainer\\checkpoint-32500\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6593, 'learning_rate': 1.937660183928841e-05, 'epoch': 1.84}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in tmp_trainer\\checkpoint-32500\\pytorch_model.bin\n",
      " 62%|██████▏   | 33000/53064 [2:57:14<2:14:48,  2.48it/s]Saving model checkpoint to tmp_trainer\\checkpoint-33000\n",
      "Configuration saved in tmp_trainer\\checkpoint-33000\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6594, 'learning_rate': 1.890547263681592e-05, 'epoch': 1.87}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in tmp_trainer\\checkpoint-33000\\pytorch_model.bin\n",
      " 63%|██████▎   | 33500/53064 [2:59:40<1:32:40,  3.52it/s]Saving model checkpoint to tmp_trainer\\checkpoint-33500\n",
      "Configuration saved in tmp_trainer\\checkpoint-33500\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6687, 'learning_rate': 1.8434343434343433e-05, 'epoch': 1.89}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in tmp_trainer\\checkpoint-33500\\pytorch_model.bin\n",
      " 64%|██████▍   | 34000/53064 [3:01:39<1:04:57,  4.89it/s]Saving model checkpoint to tmp_trainer\\checkpoint-34000\n",
      "Configuration saved in tmp_trainer\\checkpoint-34000\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6558, 'learning_rate': 1.796321423187095e-05, 'epoch': 1.92}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in tmp_trainer\\checkpoint-34000\\pytorch_model.bin\n",
      " 65%|██████▌   | 34500/53064 [3:03:57<1:36:44,  3.20it/s]Saving model checkpoint to tmp_trainer\\checkpoint-34500\n",
      "Configuration saved in tmp_trainer\\checkpoint-34500\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6589, 'learning_rate': 1.7492085029398464e-05, 'epoch': 1.95}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in tmp_trainer\\checkpoint-34500\\pytorch_model.bin\n",
      " 66%|██████▌   | 35000/53064 [3:06:27<1:19:10,  3.80it/s]Saving model checkpoint to tmp_trainer\\checkpoint-35000\n",
      "Configuration saved in tmp_trainer\\checkpoint-35000\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6647, 'learning_rate': 1.7020955826925976e-05, 'epoch': 1.98}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in tmp_trainer\\checkpoint-35000\\pytorch_model.bin\n",
      " 67%|██████▋   | 35500/53064 [3:08:55<1:41:41,  2.88it/s]Saving model checkpoint to tmp_trainer\\checkpoint-35500\n",
      "Configuration saved in tmp_trainer\\checkpoint-35500\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6546, 'learning_rate': 1.654982662445349e-05, 'epoch': 2.01}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in tmp_trainer\\checkpoint-35500\\pytorch_model.bin\n",
      " 68%|██████▊   | 36000/53064 [3:11:40<1:27:44,  3.24it/s]Saving model checkpoint to tmp_trainer\\checkpoint-36000\n",
      "Configuration saved in tmp_trainer\\checkpoint-36000\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6509, 'learning_rate': 1.6078697421981004e-05, 'epoch': 2.04}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in tmp_trainer\\checkpoint-36000\\pytorch_model.bin\n",
      " 69%|██████▉   | 36500/53064 [3:14:26<1:33:32,  2.95it/s]Saving model checkpoint to tmp_trainer\\checkpoint-36500\n",
      "Configuration saved in tmp_trainer\\checkpoint-36500\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6605, 'learning_rate': 1.560756821950852e-05, 'epoch': 2.06}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in tmp_trainer\\checkpoint-36500\\pytorch_model.bin\n",
      " 70%|██████▉   | 37000/53064 [3:17:12<1:27:20,  3.07it/s]Saving model checkpoint to tmp_trainer\\checkpoint-37000\n",
      "Configuration saved in tmp_trainer\\checkpoint-37000\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6606, 'learning_rate': 1.5136439017036033e-05, 'epoch': 2.09}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in tmp_trainer\\checkpoint-37000\\pytorch_model.bin\n",
      " 71%|███████   | 37500/53064 [3:20:03<1:25:43,  3.03it/s]Saving model checkpoint to tmp_trainer\\checkpoint-37500\n",
      "Configuration saved in tmp_trainer\\checkpoint-37500\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6567, 'learning_rate': 1.4665309814563547e-05, 'epoch': 2.12}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in tmp_trainer\\checkpoint-37500\\pytorch_model.bin\n",
      " 72%|███████▏  | 38000/53064 [3:22:50<1:19:41,  3.15it/s]Saving model checkpoint to tmp_trainer\\checkpoint-38000\n",
      "Configuration saved in tmp_trainer\\checkpoint-38000\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6643, 'learning_rate': 1.419418061209106e-05, 'epoch': 2.15}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in tmp_trainer\\checkpoint-38000\\pytorch_model.bin\n",
      " 73%|███████▎  | 38500/53064 [3:25:39<1:19:55,  3.04it/s]Saving model checkpoint to tmp_trainer\\checkpoint-38500\n",
      "Configuration saved in tmp_trainer\\checkpoint-38500\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6559, 'learning_rate': 1.3723051409618576e-05, 'epoch': 2.18}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in tmp_trainer\\checkpoint-38500\\pytorch_model.bin\n",
      " 73%|███████▎  | 39000/53064 [3:28:31<1:18:28,  2.99it/s]Saving model checkpoint to tmp_trainer\\checkpoint-39000\n",
      "Configuration saved in tmp_trainer\\checkpoint-39000\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6589, 'learning_rate': 1.325192220714609e-05, 'epoch': 2.2}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in tmp_trainer\\checkpoint-39000\\pytorch_model.bin\n",
      " 74%|███████▍  | 39500/53064 [3:31:23<1:16:02,  2.97it/s]Saving model checkpoint to tmp_trainer\\checkpoint-39500\n",
      "Configuration saved in tmp_trainer\\checkpoint-39500\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6552, 'learning_rate': 1.2780793004673603e-05, 'epoch': 2.23}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in tmp_trainer\\checkpoint-39500\\pytorch_model.bin\n",
      " 75%|███████▌  | 40000/53064 [3:33:45<1:05:14,  3.34it/s]Saving model checkpoint to tmp_trainer\\checkpoint-40000\n",
      "Configuration saved in tmp_trainer\\checkpoint-40000\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6692, 'learning_rate': 1.2309663802201115e-05, 'epoch': 2.26}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in tmp_trainer\\checkpoint-40000\\pytorch_model.bin\n",
      " 76%|███████▋  | 40500/53064 [3:36:16<1:06:30,  3.15it/s]Saving model checkpoint to tmp_trainer\\checkpoint-40500\n",
      "Configuration saved in tmp_trainer\\checkpoint-40500\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6573, 'learning_rate': 1.183853459972863e-05, 'epoch': 2.29}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in tmp_trainer\\checkpoint-40500\\pytorch_model.bin\n",
      " 77%|███████▋  | 41000/53064 [3:38:46<1:16:50,  2.62it/s]Saving model checkpoint to tmp_trainer\\checkpoint-41000\n",
      "Configuration saved in tmp_trainer\\checkpoint-41000\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6573, 'learning_rate': 1.1367405397256144e-05, 'epoch': 2.32}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in tmp_trainer\\checkpoint-41000\\pytorch_model.bin\n",
      " 78%|███████▊  | 41500/53064 [3:41:36<1:03:45,  3.02it/s]Saving model checkpoint to tmp_trainer\\checkpoint-41500\n",
      "Configuration saved in tmp_trainer\\checkpoint-41500\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6524, 'learning_rate': 1.0896276194783658e-05, 'epoch': 2.35}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in tmp_trainer\\checkpoint-41500\\pytorch_model.bin\n",
      " 79%|███████▉  | 42000/53064 [3:44:23<1:01:11,  3.01it/s]Saving model checkpoint to tmp_trainer\\checkpoint-42000\n",
      "Configuration saved in tmp_trainer\\checkpoint-42000\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6635, 'learning_rate': 1.0425146992311172e-05, 'epoch': 2.37}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in tmp_trainer\\checkpoint-42000\\pytorch_model.bin\n",
      " 80%|████████  | 42500/53064 [3:47:08<56:28,  3.12it/s]Saving model checkpoint to tmp_trainer\\checkpoint-42500\n",
      "Configuration saved in tmp_trainer\\checkpoint-42500\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6561, 'learning_rate': 9.954017789838687e-06, 'epoch': 2.4}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in tmp_trainer\\checkpoint-42500\\pytorch_model.bin\n",
      " 81%|████████  | 43000/53064 [3:49:57<56:00,  2.99it/s]Saving model checkpoint to tmp_trainer\\checkpoint-43000\n",
      "Configuration saved in tmp_trainer\\checkpoint-43000\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6644, 'learning_rate': 9.482888587366199e-06, 'epoch': 2.43}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in tmp_trainer\\checkpoint-43000\\pytorch_model.bin\n",
      " 82%|████████▏ | 43500/53064 [3:52:45<49:15,  3.24it/s]Saving model checkpoint to tmp_trainer\\checkpoint-43500\n",
      "Configuration saved in tmp_trainer\\checkpoint-43500\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6556, 'learning_rate': 9.011759384893715e-06, 'epoch': 2.46}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in tmp_trainer\\checkpoint-43500\\pytorch_model.bin\n",
      " 83%|████████▎ | 44000/53064 [3:55:34<50:13,  3.01it/s]Saving model checkpoint to tmp_trainer\\checkpoint-44000\n",
      "Configuration saved in tmp_trainer\\checkpoint-44000\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6541, 'learning_rate': 8.540630182421228e-06, 'epoch': 2.49}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in tmp_trainer\\checkpoint-44000\\pytorch_model.bin\n",
      " 84%|████████▍ | 44500/53064 [3:58:25<46:56,  3.04it/s]Saving model checkpoint to tmp_trainer\\checkpoint-44500\n",
      "Configuration saved in tmp_trainer\\checkpoint-44500\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6527, 'learning_rate': 8.06950097994874e-06, 'epoch': 2.52}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in tmp_trainer\\checkpoint-44500\\pytorch_model.bin\n",
      " 85%|████████▍ | 45000/53064 [4:01:13<44:41,  3.01it/s]Saving model checkpoint to tmp_trainer\\checkpoint-45000\n",
      "Configuration saved in tmp_trainer\\checkpoint-45000\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6578, 'learning_rate': 7.598371777476256e-06, 'epoch': 2.54}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in tmp_trainer\\checkpoint-45000\\pytorch_model.bin\n",
      " 86%|████████▌ | 45500/53064 [4:04:01<44:14,  2.85it/s]Saving model checkpoint to tmp_trainer\\checkpoint-45500\n",
      "Configuration saved in tmp_trainer\\checkpoint-45500\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6583, 'learning_rate': 7.1272425750037685e-06, 'epoch': 2.57}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in tmp_trainer\\checkpoint-45500\\pytorch_model.bin\n",
      " 87%|████████▋ | 46000/53064 [4:06:51<38:54,  3.03it/s]Saving model checkpoint to tmp_trainer\\checkpoint-46000\n",
      "Configuration saved in tmp_trainer\\checkpoint-46000\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6598, 'learning_rate': 6.656113372531283e-06, 'epoch': 2.6}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in tmp_trainer\\checkpoint-46000\\pytorch_model.bin\n",
      " 88%|████████▊ | 46500/53064 [4:09:39<34:16,  3.19it/s]Saving model checkpoint to tmp_trainer\\checkpoint-46500\n",
      "Configuration saved in tmp_trainer\\checkpoint-46500\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6548, 'learning_rate': 6.184984170058798e-06, 'epoch': 2.63}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in tmp_trainer\\checkpoint-46500\\pytorch_model.bin\n",
      " 89%|████████▊ | 47000/53064 [4:12:31<32:43,  3.09it/s]Saving model checkpoint to tmp_trainer\\checkpoint-47000\n",
      "Configuration saved in tmp_trainer\\checkpoint-47000\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.652, 'learning_rate': 5.7138549675863105e-06, 'epoch': 2.66}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in tmp_trainer\\checkpoint-47000\\pytorch_model.bin\n",
      " 90%|████████▉ | 47500/53064 [4:14:54<20:05,  4.62it/s]Saving model checkpoint to tmp_trainer\\checkpoint-47500\n",
      "Configuration saved in tmp_trainer\\checkpoint-47500\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.656, 'learning_rate': 5.242725765113825e-06, 'epoch': 2.69}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in tmp_trainer\\checkpoint-47500\\pytorch_model.bin\n",
      " 90%|█████████ | 48000/53064 [4:16:42<17:53,  4.72it/s]Saving model checkpoint to tmp_trainer\\checkpoint-48000\n",
      "Configuration saved in tmp_trainer\\checkpoint-48000\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6606, 'learning_rate': 4.771596562641339e-06, 'epoch': 2.71}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in tmp_trainer\\checkpoint-48000\\pytorch_model.bin\n",
      " 91%|█████████▏| 48500/53064 [4:18:35<15:55,  4.78it/s]Saving model checkpoint to tmp_trainer\\checkpoint-48500\n",
      "Configuration saved in tmp_trainer\\checkpoint-48500\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.663, 'learning_rate': 4.3004673601688526e-06, 'epoch': 2.74}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in tmp_trainer\\checkpoint-48500\\pytorch_model.bin\n",
      " 92%|█████████▏| 49000/53064 [4:20:26<14:33,  4.65it/s]Saving model checkpoint to tmp_trainer\\checkpoint-49000\n",
      "Configuration saved in tmp_trainer\\checkpoint-49000\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6584, 'learning_rate': 3.829338157696367e-06, 'epoch': 2.77}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in tmp_trainer\\checkpoint-49000\\pytorch_model.bin\n",
      " 93%|█████████▎| 49500/53064 [4:22:40<17:43,  3.35it/s]Saving model checkpoint to tmp_trainer\\checkpoint-49500\n",
      "Configuration saved in tmp_trainer\\checkpoint-49500\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6565, 'learning_rate': 3.358208955223881e-06, 'epoch': 2.8}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in tmp_trainer\\checkpoint-49500\\pytorch_model.bin\n",
      " 94%|█████████▍| 50000/53064 [4:25:00<11:05,  4.61it/s]Saving model checkpoint to tmp_trainer\\checkpoint-50000\n",
      "Configuration saved in tmp_trainer\\checkpoint-50000\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6559, 'learning_rate': 2.8870797527513946e-06, 'epoch': 2.83}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in tmp_trainer\\checkpoint-50000\\pytorch_model.bin\n",
      " 95%|█████████▌| 50500/53064 [4:28:03<13:46,  3.10it/s]Saving model checkpoint to tmp_trainer\\checkpoint-50500\n",
      "Configuration saved in tmp_trainer\\checkpoint-50500\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6504, 'learning_rate': 2.4159505502789087e-06, 'epoch': 2.86}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in tmp_trainer\\checkpoint-50500\\pytorch_model.bin\n",
      " 96%|█████████▌| 51000/53064 [4:30:56<11:24,  3.01it/s]Saving model checkpoint to tmp_trainer\\checkpoint-51000\n",
      "Configuration saved in tmp_trainer\\checkpoint-51000\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6569, 'learning_rate': 1.944821347806423e-06, 'epoch': 2.88}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in tmp_trainer\\checkpoint-51000\\pytorch_model.bin\n",
      " 97%|█████████▋| 51500/53064 [4:33:46<08:48,  2.96it/s]Saving model checkpoint to tmp_trainer\\checkpoint-51500\n",
      "Configuration saved in tmp_trainer\\checkpoint-51500\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6594, 'learning_rate': 1.4736921453339366e-06, 'epoch': 2.91}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in tmp_trainer\\checkpoint-51500\\pytorch_model.bin\n",
      " 98%|█████████▊| 52000/53064 [4:36:36<06:00,  2.95it/s]Saving model checkpoint to tmp_trainer\\checkpoint-52000\n",
      "Configuration saved in tmp_trainer\\checkpoint-52000\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6546, 'learning_rate': 1.0025629428614503e-06, 'epoch': 2.94}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in tmp_trainer\\checkpoint-52000\\pytorch_model.bin\n",
      " 99%|█████████▉| 52500/53064 [4:39:29<03:11,  2.95it/s]Saving model checkpoint to tmp_trainer\\checkpoint-52500\n",
      "Configuration saved in tmp_trainer\\checkpoint-52500\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6574, 'learning_rate': 5.314337403889643e-07, 'epoch': 2.97}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in tmp_trainer\\checkpoint-52500\\pytorch_model.bin\n",
      "100%|█████████▉| 53000/53064 [4:42:22<00:21,  2.98it/s]Saving model checkpoint to tmp_trainer\\checkpoint-53000\n",
      "Configuration saved in tmp_trainer\\checkpoint-53000\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6524, 'learning_rate': 6.030453791647821e-08, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in tmp_trainer\\checkpoint-53000\\pytorch_model.bin\n",
      "100%|██████████| 53064/53064 [4:42:47<00:00,  2.98it/s]\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "100%|██████████| 53064/53064 [4:42:47<00:00,  3.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 16967.8019, 'train_samples_per_second': 25.018, 'train_steps_per_second': 3.127, 'train_loss': 0.6604022006364533, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=53064, training_loss=0.6604022006364533, metrics={'train_runtime': 16967.8019, 'train_samples_per_second': 25.018, 'train_steps_per_second': 3.127, 'train_loss': 0.6604022006364533, 'epoch': 3.0})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train\n",
    "trainer = Trainer(model=model, train_dataset=encoded_train, eval_dataset=encoded_validation)\n",
    "\n",
    "trainer.train()    \n",
    "#trainer.train(resume_from_checkpoint=True) # True if already trained, to save time by continuing on a checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in simcse_qqp\\config.json\n",
      "Model weights saved in simcse_qqp\\pytorch_model.bin\n"
     ]
    }
   ],
   "source": [
    "# save the fine_tuned model\n",
    "model.save_pretrained(\"simcse_qqp\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default\n",
      "Reusing dataset quora (C:\\Users\\52673\\.cache\\huggingface\\datasets\\quora\\default\\0.0.0\\36ba4cd42107f051a158016f1bea6ae3f4685c5df843529108a54e42d86c1e04)\n",
      "Using custom data configuration default\n",
      "Reusing dataset quora (C:\\Users\\52673\\.cache\\huggingface\\datasets\\quora\\default\\0.0.0\\36ba4cd42107f051a158016f1bea6ae3f4685c5df843529108a54e42d86c1e04)\n",
      "Loading cached processed dataset at C:\\Users\\52673\\.cache\\huggingface\\datasets\\quora\\default\\0.0.0\\36ba4cd42107f051a158016f1bea6ae3f4685c5df843529108a54e42d86c1e04\\cache-58ce8a2d3d13bc51.arrow\n",
      "Loading cached processed dataset at C:\\Users\\52673\\.cache\\huggingface\\datasets\\quora\\default\\0.0.0\\36ba4cd42107f051a158016f1bea6ae3f4685c5df843529108a54e42d86c1e04\\cache-077de9dbe62a5b12.arrow\n",
      "Loading cached processed dataset at C:\\Users\\52673\\.cache\\huggingface\\datasets\\quora\\default\\0.0.0\\36ba4cd42107f051a158016f1bea6ae3f4685c5df843529108a54e42d86c1e04\\cache-aec8ebd6b027502c.arrow\n",
      "Loading cached processed dataset at C:\\Users\\52673\\.cache\\huggingface\\datasets\\quora\\default\\0.0.0\\36ba4cd42107f051a158016f1bea6ae3f4685c5df843529108a54e42d86c1e04\\cache-51760f038d5f8ea5.arrow\n"
     ]
    }
   ],
   "source": [
    "# sampling the evaluation dataset from QQP\n",
    "train_eval = load_dataset(\"quora\", split = 'train[50%:85%]')\n",
    "validation_eval = load_dataset(\"quora\", split = 'train[85%:100%]')\n",
    "\n",
    "# repeat all the preprocessing steps above\n",
    "new_features = train_eval.features.copy()\n",
    "new_features[\"is_duplicate\"] = Value('int32')\n",
    "train_eval = train_eval.cast(new_features)\n",
    "\n",
    "new_features = validation_eval.features.copy()\n",
    "new_features[\"is_duplicate\"] = Value('int32')\n",
    "validation_eval = validation_eval.cast(new_features)\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained('bert-base-cased')\n",
    "\n",
    "\n",
    "# encode the training dataset in the form of sentences pair\n",
    "encoded_train_eval = train_eval.map(lambda batch: tokenizer(batch['questions']['text'][0], batch['questions']['text'][1], \n",
    "                                                  padding='max_length', truncation=True, max_length=64))\n",
    "encoded_train_eval.rename_column_(\"is_duplicate\", \"labels\")\n",
    "\n",
    "# encode the validation dataset in the form of sentences pair\n",
    "encoded_validation_eval = validation_eval.map(lambda batch: tokenizer(batch['questions']['text'][0], batch['questions']['text'][1], \n",
    "                                                            padding='max_length', truncation=True, max_length=64))\n",
    "encoded_validation_eval.rename_column_(\"is_duplicate\", \"labels\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the fine-tuned CL-BERT model\n",
    "simcse_qqp = AutoModelForSequenceClassification.from_pretrained(\"simcse_qqp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the metric module to compute accuracy\n",
    "accuracy = load_metric(\"accuracy\")\n",
    "\n",
    "def compute_accuracy(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    return accuracy.compute(predictions=predictions, references=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the metric module to compute f1 score\n",
    "f1 = load_metric(\"f1\")\n",
    "\n",
    "def compute_f1(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    return f1.compute(predictions=predictions, references=labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: questions.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 60644\n",
      "  Batch size = 8\n",
      "100%|██████████| 7581/7581 [08:48<00:00, 14.33it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.6635891199111938,\n",
       " 'eval_accuracy': 0.6436745597256117,\n",
       " 'eval_runtime': 531.4313,\n",
       " 'eval_samples_per_second': 114.114,\n",
       " 'eval_steps_per_second': 14.265}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer_qqp = Trainer(\n",
    "    model=simcse_qqp,    #use the fine-tuned model saved on\n",
    "    train_dataset=encoded_train_eval,\n",
    "    eval_dataset=encoded_validation_eval,\n",
    "    compute_metrics=compute_accuracy,\n",
    ")\n",
    "\n",
    "trainer_qqp.evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## F1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No `TrainingArguments` passed, using `output_dir=tmp_trainer`.\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: questions.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 60644\n",
      "  Batch size = 8\n",
      "100%|██████████| 7581/7581 [12:49<00:00,  9.85it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.6635891199111938,\n",
       " 'eval_f1': 0.0,\n",
       " 'eval_runtime': 769.8367,\n",
       " 'eval_samples_per_second': 78.775,\n",
       " 'eval_steps_per_second': 9.848}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer_qqp = Trainer(\n",
    "    model=simcse_qqp,    #use the fine-tuned model saved on\n",
    "    train_dataset=encoded_train_eval,\n",
    "    eval_dataset=encoded_validation_eval,\n",
    "    compute_metrics=compute_f1,\n",
    ")\n",
    "\n",
    "trainer_qqp.evaluate() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "01cce90487304195a98c1fadead284adb0ca16778f239acdcba59c3951b79f2e"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
